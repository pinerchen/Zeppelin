{"paragraphs":[{"text":"%dep\r\nz.load(\"org.scalanlp:jblas:1.2.1\")","user":"anonymous","dateUpdated":"2018-12-10T08:53:19+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"res0: org.apache.zeppelin.dep.Dependency = org.apache.zeppelin.dep.Dependency@1defd527\n"}]},"apps":[],"jobName":"paragraph_1544408239254_-2129669001","id":"20181207-014033_1320992749","dateCreated":"2018-12-10T02:17:19+0000","dateStarted":"2018-12-10T02:33:01+0000","dateFinished":"2018-12-10T02:33:13+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:4602"},{"text":"// 导入jblas库中的矩阵类\nimport org.jblas.DoubleMatrix\n// 定义相似度函数\ndef cosineSimilarity(vec1: DoubleMatrix, vec2: DoubleMatrix): Double = {\n    vec1.dot(vec2) / (vec1.norm2() * vec2.norm2())\n}\n","user":"anonymous","dateUpdated":"2018-12-10T02:33:16+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.jblas.DoubleMatrix\ncosineSimilarity: (vec1: org.jblas.DoubleMatrix, vec2: org.jblas.DoubleMatrix)Double\n"}]},"apps":[],"jobName":"paragraph_1544408239260_-1000475953","id":"20181207-014114_1651130668","dateCreated":"2018-12-10T02:17:19+0000","dateStarted":"2018-12-10T02:33:16+0000","dateFinished":"2018-12-10T02:33:48+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4603"},{"text":"import java.io.File\nimport scala.io.Source\nimport org.apache.log4j.Logger\nimport org.apache.log4j.Level\n\nimport org.apache.spark.ml.fpm.FPGrowth\nimport org.apache.spark.ml.feature.StringIndexer\nimport org.apache.spark.ml.feature.VectorAssembler\nimport org.apache.spark.broadcast.Broadcast\nimport org.apache.spark.ml.evaluation.RegressionEvaluator\n\nimport org.apache.spark.sql.functions._\nimport org.apache.spark.sql.functions.explode\nimport org.apache.spark.sql.{DataFrame, Dataset,SparkSession}","user":"anonymous","dateUpdated":"2018-12-10T02:33:58+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import java.io.File\nimport scala.io.Source\nimport org.apache.log4j.Logger\nimport org.apache.log4j.Level\nimport org.apache.spark.ml.fpm.FPGrowth\nimport org.apache.spark.ml.feature.StringIndexer\nimport org.apache.spark.ml.feature.VectorAssembler\nimport org.apache.spark.broadcast.Broadcast\nimport org.apache.spark.ml.evaluation.RegressionEvaluator\nimport org.apache.spark.sql.functions._\nimport org.apache.spark.sql.functions.explode\nimport org.apache.spark.sql.{DataFrame, Dataset, SparkSession}\n"}]},"apps":[],"jobName":"paragraph_1544408239261_1250066592","id":"20181207-015202_1846790921","dateCreated":"2018-12-10T02:17:19+0000","dateStarted":"2018-12-10T02:33:58+0000","dateFinished":"2018-12-10T02:34:01+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4604"},{"text":"import org.apache.spark.mllib.recommendation.Rating\nimport org.apache.spark.mllib.recommendation.ALS\nimport org.apache.spark.mllib.recommendation.MatrixFactorizationModel\nimport org.apache.spark.sql.Row\n\nimport org.apache.spark.SparkConf\nimport org.apache.spark.SparkContext\nimport org.apache.spark.SparkContext._\nimport org.apache.spark.broadcast.Broadcast\nimport org.apache.spark.rdd.RDD","user":"anonymous","dateUpdated":"2018-12-10T03:53:27+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.apache.spark.mllib.recommendation.Rating\nimport org.apache.spark.mllib.recommendation.ALS\nimport org.apache.spark.mllib.recommendation.MatrixFactorizationModel\nimport org.apache.spark.sql.Row\nimport org.apache.spark.SparkConf\nimport org.apache.spark.SparkContext\nimport org.apache.spark.SparkContext._\nimport org.apache.spark.broadcast.Broadcast\nimport org.apache.spark.rdd.RDD\n"}]},"apps":[],"jobName":"paragraph_1544408239262_-998670931","id":"20181206-015555_1654254797","dateCreated":"2018-12-10T02:17:19+0000","dateStarted":"2018-12-10T03:53:27+0000","dateFinished":"2018-12-10T03:53:28+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4605"},{"text":"import org.apache.spark.rdd.RDD","user":"anonymous","dateUpdated":"2018-12-10T03:53:59+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.apache.spark.rdd.RDD\n"}]},"apps":[],"jobName":"paragraph_1544414036121_1060703778","id":"20181210-035356_41865601","dateCreated":"2018-12-10T03:53:56+0000","dateStarted":"2018-12-10T03:53:59+0000","dateFinished":"2018-12-10T03:53:59+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4606"},{"text":"import org.apache.spark.sql.functions._\nval transaction = spark.read.option(\"header\",\"true\").csv(\"s3://input-smart-find/Quotations-110818-S.csv\").select($\"Quotation: Quotation ID\".alias(\"user\"), $\"Product: Product Family\".alias(\"product\"),$\"Display Quantity\".alias(\"number\")).groupBy(\"user\",\"product\").agg(sum(\"number\").alias(\"rating\")).toDF()\n\n","user":"anonymous","dateUpdated":"2018-12-10T02:34:16+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.apache.spark.sql.functions._\ntransaction: org.apache.spark.sql.DataFrame = [user: string, product: string ... 1 more field]\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=0"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1544408239262_1572331508","id":"20181206-031602_2120750532","dateCreated":"2018-12-10T02:17:19+0000","dateStarted":"2018-12-10T02:34:16+0000","dateFinished":"2018-12-10T02:34:47+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4607"},{"text":"// load product description dataset\n val product_description = spark.read.option(\"header\",\"true\").csv(\"s3://input-smart-find/products - 110818-s.csv\").select($\"Product Family\".alias(\"product\"), $\"Product Description\".alias(\"product_description\"))","user":"anonymous","dateUpdated":"2018-12-10T03:23:08+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"product_description: org.apache.spark.sql.DataFrame = [product: string, product_description: string]\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=14"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1544408239263_939711241","id":"20181206-050321_333714499","dateCreated":"2018-12-10T02:17:19+0000","dateStarted":"2018-12-10T03:23:08+0000","dateFinished":"2018-12-10T03:23:18+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4608"},{"text":"// create unique userID and productID\nval userIndexer = new StringIndexer().setInputCol(\"user\").setOutputCol(\"userID\")\nval indexed = userIndexer.fit(transaction).transform(transaction)\nval productIndexer = new StringIndexer().setInputCol(\"product\").setOutputCol(\"productID\")\nval whole = productIndexer.fit(indexed).transform(indexed)\nwhole.printSchema()\nwhole.show(10)\nval transform = whole.select($\"userID\".cast(\"int\"),$\"productID\".cast(\"int\"),$\"rating\")\nval table = transform.groupBy(\"userID\",\"productID\").agg(sum(\"rating\").alias(\"rating\")).toDF()","user":"anonymous","dateUpdated":"2018-12-10T02:35:04+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"userIndexer: org.apache.spark.ml.feature.StringIndexer = strIdx_9d2aad1a5f10\nindexed: org.apache.spark.sql.DataFrame = [user: string, product: string ... 2 more fields]\nproductIndexer: org.apache.spark.ml.feature.StringIndexer = strIdx_7e5a483d6a86\nwhole: org.apache.spark.sql.DataFrame = [user: string, product: string ... 3 more fields]\nroot\n |-- user: string (nullable = true)\n |-- product: string (nullable = true)\n |-- rating: double (nullable = true)\n |-- userID: double (nullable = false)\n |-- productID: double (nullable = false)\n\n+----------+----------+------+-------+---------+\n|      user|   product|rating| userID|productID|\n+----------+----------+------+-------+---------+\n|Q-00006876|10MQS79500| 150.0| 3545.0|  12144.0|\n|Q-00004324|4Z90Q25510| 500.0| 7696.0|  21270.0|\n|Q-00018356|10LKPAT6EU|  16.0| 5969.0|   1140.0|\n|Q-00028520|4X30H56828|   5.0|14868.0|    231.0|\n|Q-00009760|4XH0N04885| 100.0|13316.0|    746.0|\n|Q-00022082|   0A36536|  50.0| 2245.0|     61.0|\n|Q-00063689|   39Y7937|   4.0| 4971.0|    123.0|\n|Q-00017806|10QYPAT1UK| 500.0|12599.0|     29.0|\n|Q-00074595|7Y37A01086|   1.0|  591.0|    452.0|\n|Q-00054445|61A6MAT3EU|  15.0|17770.0|      7.0|\n+----------+----------+------+-------+---------+\nonly showing top 10 rows\n\ntransform: org.apache.spark.sql.DataFrame = [userID: int, productID: int ... 1 more field]\ntable: org.apache.spark.sql.DataFrame = [userID: int, productID: int ... 1 more field]\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=1","http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=2","http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=3"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1544408239263_1060861418","id":"20181206-032238_531768591","dateCreated":"2018-12-10T02:17:19+0000","dateStarted":"2018-12-10T02:35:04+0000","dateFinished":"2018-12-10T02:36:30+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4609"},{"text":"table.describe().show()","user":"anonymous","dateUpdated":"2018-12-10T02:17:19+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+-------+-----------------+-----------------+------------------+\n|summary|           userID|        productID|            rating|\n+-------+-----------------+-----------------+------------------+\n|  count|           140062|           140062|            140062|\n|   mean|6952.679763247705| 3182.26753866145|211.59446530822063|\n| stddev|8414.775901249903|5448.523067208439| 704.5583437444309|\n|    min|                0|                0|               0.0|\n|    max|            33983|            24208|           30000.0|\n+-------+-----------------+-----------------+------------------+\n\n"}]},"apps":[],"jobName":"paragraph_1544408239264_-177086648","id":"20181207-020734_1436817550","dateCreated":"2018-12-10T02:17:19+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:4610"},{"text":"// NOTE: add minimum and maximum values to thresholds\r\nval thresholds: Array[Double] = Array(Double.MinValue, 0.0) ++ (((0.0 until 30000 by 1000).toArray ++ Array(Double.MaxValue)).map(_.toDouble))\r\n\r\n// Convert DataFrame to RDD and calculate histogram values\r\nval _tmpHist = whole.\r\n    select($\"rating\" cast \"double\").\r\n    rdd.map(r => r.getDouble(0)).\r\n    histogram(thresholds)\r\n\r\n// Result DataFrame contains `from`, `to` range and the `value`.\r\nval histogram = sc.parallelize((thresholds, thresholds.tail, _tmpHist).zipped.toList).toDF(\"from\", \"to\", \"value\")","user":"anonymous","dateUpdated":"2018-12-10T03:09:16+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"thresholds: Array[Double] = Array(-1.7976931348623157E308, 0.0, 0.0, 1000.0, 2000.0, 3000.0, 4000.0, 5000.0, 6000.0, 7000.0, 8000.0, 9000.0, 10000.0, 11000.0, 12000.0, 13000.0, 14000.0, 15000.0, 16000.0, 17000.0, 18000.0, 19000.0, 20000.0, 21000.0, 22000.0, 23000.0, 24000.0, 25000.0, 26000.0, 27000.0, 28000.0, 29000.0, 1.7976931348623157E308)\n_tmpHist: Array[Long] = Array(0, 7, 133360, 4167, 1192, 371, 345, 265, 78, 42, 118, 8, 39, 6, 11, 2, 2, 10, 4, 1, 0, 4, 13, 4, 0, 0, 1, 1, 0, 0, 2, 9)\nhistogram: org.apache.spark.sql.DataFrame = [from: double, to: double ... 1 more field]\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=10"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1544411144670_-844905843","id":"20181210-030544_1874757063","dateCreated":"2018-12-10T03:05:44+0000","dateStarted":"2018-12-10T03:09:16+0000","dateFinished":"2018-12-10T03:09:36+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4611"},{"text":"// 產品購買數量分布\nhistogram.sort($\"value\".desc).show()","user":"anonymous","dateUpdated":"2018-12-10T03:15:10+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+-------+--------------------+------+\n|   from|                  to| value|\n+-------+--------------------+------+\n|    0.0|              1000.0|133360|\n| 1000.0|              2000.0|  4167|\n| 2000.0|              3000.0|  1192|\n| 3000.0|              4000.0|   371|\n| 4000.0|              5000.0|   345|\n| 5000.0|              6000.0|   265|\n| 8000.0|              9000.0|   118|\n| 6000.0|              7000.0|    78|\n| 7000.0|              8000.0|    42|\n|10000.0|             11000.0|    39|\n|20000.0|             21000.0|    13|\n|12000.0|             13000.0|    11|\n|15000.0|             16000.0|    10|\n|29000.0|1.797693134862315...|     9|\n| 9000.0|             10000.0|     8|\n|    0.0|                 0.0|     7|\n|11000.0|             12000.0|     6|\n|19000.0|             20000.0|     4|\n|16000.0|             17000.0|     4|\n|21000.0|             22000.0|     4|\n+-------+--------------------+------+\nonly showing top 20 rows\n\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=13"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1544411528231_1349450587","id":"20181210-031208_562292783","dateCreated":"2018-12-10T03:12:08+0000","dateStarted":"2018-12-10T03:14:05+0000","dateFinished":"2018-12-10T03:14:13+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4612"},{"text":"whole.sort($\"rating\".asc).show ","user":"anonymous","dateUpdated":"2018-12-10T10:13:58+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+----------+----------+------+-------+---------+\n|      user|   product|rating| userID|productID|\n+----------+----------+------+-------+---------+\n|Q-00043411|20L9001YMX|   0.0| 4474.0|    975.0|\n|Q-00043411|20L7001VMX|   0.0| 4474.0|    414.0|\n|Q-00043411|40AC0135EU|   0.0| 4474.0|      9.0|\n|Q-00043411|40AJ0135EU|   0.0| 4474.0|     13.0|\n|Q-00043411|20L7001SMX|   0.0| 4474.0|   1361.0|\n|Q-00043411|80XF008QMX|   0.0| 4474.0|   2082.0|\n|Q-00043411|20L90021MX|   0.0| 4474.0|   2929.0|\n|Q-00022983|40AC0135UK|   1.0|12579.0|     50.0|\n|Q-00043408|20HMS70200|   1.0| 1193.0|  20496.0|\n|Q-00018855|   06P4069|   1.0| 5305.0|      5.0|\n|Q-00051756|20KF002URT|   1.0| 1912.0|   2226.0|\n|Q-00075233|   01KP939|   1.0|  553.0|   2457.0|\n|Q-00026754|61B1JAT1UK|   1.0| 3460.0|    140.0|\n|Q-00051279|10QXPAT1UK|   1.0| 8166.0|    138.0|\n|Q-00028664|7X99A039EA|   1.0|  532.0|   4625.0|\n|Q-00026425|   0C52863|   1.0|30674.0|    237.0|\n|Q-00013397|4X40E77328|   1.0| 3421.0|      0.0|\n|Q-00019666|   0B46994|   1.0|23231.0|   2558.0|\n|Q-00062951|   0A61769|   1.0| 3879.0|     56.0|\n|Q-00034559|   3633EUG|   1.0|  366.0|  21280.0|\n+----------+----------+------+-------+---------+\nonly showing top 20 rows\n\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=459"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1544436823915_1211881045","id":"20181210-101343_2141680686","dateCreated":"2018-12-10T10:13:43+0000","dateStarted":"2018-12-10T10:13:58+0000","dateFinished":"2018-12-10T10:14:11+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4613"},{"text":"// filter某用戶在某產品購買數量最多的紀錄\n//whole.sort($\"rating\".desc).show \n/*\n+----------+----------+-------+-------+---------+\n|      user|   product| rating| userID|productID|\n+----------+----------+-------+-------+---------+\n|Q-00030883|10QYPAT1EU|30000.0|14060.0|     26.0|\n|Q-00063632|61B7JAT6EU|30000.0|17747.0|     60.0|\n|Q-00063632|61CAKAT1EU|30000.0|17747.0|    207.0|\n|Q-00030883|10M4S00R00|30000.0|14060.0|  10806.0|\n|Q-00068476|20LTS6P200|29200.0|10726.0|  23877.0|\n+----------+----------+-------+-------+---------+\n*/\n\n\n// filter 消費數量最高的前10大用戶\n//whole.groupBy(\"userID\").agg(sum(\"rating\").alias(\"Total_Amount\")).sort($\"Total_Amount\".desc).show\n/*\n+------+------------+\n|userID|Total_Amount|\n+------+------------+\n|   3.0|    537000.0|\n|  54.0|    344450.0|\n| 282.0|    250800.0|\n| 334.0|    230800.0|\n|  71.0|    173000.0|\n| 719.0|    170800.0|\n|1054.0|    160000.0|\n| 685.0|    158000.0|\n| 707.0|    154000.0|\n| 760.0|    148000.0|\n+------+------------+\n\n*/\n\n// top 10 sale\nwhole.groupBy(\"productID\").agg(sum(\"rating\").alias(\"Total_Amount\")).sort($\"Total_Amount\".desc).show\n/*\n+---------+------------+\n|productID|Total_Amount|\n+---------+------------+\n|      0.0|    577598.0|\n|      1.0|    492920.0|\n|      5.0|    288709.0|\n|      4.0|    272528.0|\n|      3.0|    262920.0|\n|      8.0|    236287.0|\n|     18.0|    228088.0|\n|     11.0|    221678.0|\n|      2.0|    213747.0|\n|    153.0|    201092.0|\n+---------+------------+\n\n*/","user":"anonymous","dateUpdated":"2018-12-10T08:54:33+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+---------+------------+\n|productID|Total_Amount|\n+---------+------------+\n|      0.0|    577598.0|\n|      1.0|    492920.0|\n|      5.0|    288709.0|\n|      4.0|    272528.0|\n|      3.0|    262920.0|\n|      8.0|    236287.0|\n|     18.0|    228088.0|\n|     11.0|    221678.0|\n|      2.0|    213747.0|\n|    153.0|    201092.0|\n|     12.0|    190404.0|\n|      7.0|    186119.0|\n|     10.0|    171623.0|\n|     29.0|    171162.0|\n|     26.0|    159098.0|\n|     25.0|    157461.0|\n|     43.0|    153815.0|\n|     20.0|    149403.0|\n|     58.0|    149296.0|\n|     92.0|    145761.0|\n+---------+------------+\nonly showing top 20 rows\n\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=6"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1544409813111_795493048","id":"20181210-024333_662134430","dateCreated":"2018-12-10T02:43:33+0000","dateStarted":"2018-12-10T02:58:17+0000","dateFinished":"2018-12-10T02:59:27+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4614"},{"text":"// top 5 sale product details\nfor (products <- Array(0,1,5,4,3)) {\n     //val product_detail = product_name(products)\n     val product_string = product_detail(products)\n    println(\"productID: \" + products + \"= \" + \" :\" + product_string)\n    }\n    ","user":"anonymous","dateUpdated":"2018-12-10T03:52:32+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"productID: 0=  :CASE_BO Essential Top load\nproductID: 1=  :Thinkpad USB-C Dock\nproductID: 5=  :MOUSE OPTICAL WHEEL\nproductID: 4=  :CASE_BO Essential Backpack\nproductID: 3=  :Thinkpad USB-C Dock\n"}]},"apps":[],"jobName":"paragraph_1544411835128_-1290573071","id":"20181210-031715_1073080551","dateCreated":"2018-12-10T03:17:15+0000","dateStarted":"2018-12-10T03:51:37+0000","dateFinished":"2018-12-10T03:51:37+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4615"},{"text":"val productMapping = whole.select($\"product\",$\"productID\")\nval userMapping = whole.select($\"user\",$\"userID\")\nval product_name = productMapping.rdd.map(r => (r(1),r(0))).collectAsMap()\nval user_name = userMapping.rdd.map(r => (r(1),r(0))).collectAsMap()\nproduct_name(0)\nuser_name(1)","user":"anonymous","dateUpdated":"2018-12-10T03:21:08+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":6,"editorMode":"ace/mode/scala","fontSize":9,"results":{"0":{"graph":{"mode":"table","height":88,"optionOpen":false}}},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"productMapping: org.apache.spark.sql.DataFrame = [product: string, productID: double]\nuserMapping: org.apache.spark.sql.DataFrame = [user: string, userID: double]\nproduct_name: scala.collection.Map[Any,Any] = Map(12572.0 -> 20L6SC4G00, 3672.0 -> 7X15A02BEA, 6938.0 -> 20EQS6EK00, 6220.0 -> 30BGS1D300, 12886.0 -> 20LJS15N00, 3331.0 -> 0B47039, 5879.0 -> 20HMS0T800, 2990.0 -> 30BH0002GE, 5538.0 -> 20JH002RIX, 5197.0 -> 20JRS0LY00, 18090.0 -> 10R50000UK, 24038.0 -> 20LA001SMX, 18404.0 -> 10MAS4KW00, 20952.0 -> 20KH006JSC, 17749.0 -> 00MJ101, 23697.0 -> ZA2K0132RU, 18063.0 -> 7SD7A05750, 14797.0 -> 953292G, 17408.0 -> 20MAS0FR00, 20611.0 -> 10NNS1DJ00, 24011.0 -> 20M7S01L00, 23356.0 -> 20HES6W600, 17722.0 -> 20LD002HMH, 17004.0 -> 30B6S22H00, 20270.0 -> 10MNS3C200, 19615.0 -> 20HLS32D00, 23670.0 -> 20HES2Y200, 10715.0 -> 20J5S2BF00, 16663.0 -> 20JB0017PG, 19929.0 -> 20K5S37309, 19274.0 -> 20HH0016MB, 19211.0 -> 20LXS2D600, 10374.0 -> 20J5S1L200, 12922...user_name: scala.collection.Map[Any,Any] = Map(12572.0 -> Q-00061484, 29520.0 -> Q-00066752, 3672.0 -> Q-00062586, 6938.0 -> Q-00017424, 32068.0 -> Q-00041051, 6220.0 -> Q-00055408, 12886.0 -> Q-00005916, 32382.0 -> Q-00074731, 3331.0 -> Q-00071843, 5879.0 -> Q-00061896, 31727.0 -> Q-00041897, 2990.0 -> Q-00037053, 32041.0 -> Q-00006028, 31386.0 -> Q-00060865, 5538.0 -> Q-00068442, 33934.0 -> Q-00073795, 25097.0 -> Q-00031200, 27645.0 -> Q-00031969, 24379.0 -> Q-00070108, 31045.0 -> Q-00047439, 5197.0 -> Q-00040088, 33593.0 -> Q-00062548, 18090.0 -> Q-00042313, 24693.0 -> Q-00068425, 27304.0 -> Q-00035694, 24038.0 -> Q-00045374, 18404.0 -> Q-00063263, 20952.0 -> Q-00014478, 33252.0 -> Q-00025044, 17749.0 -> Q-00003973, 24352.0 -> Q-00062613, 27618.0 -> Q-00054686, 23697.0 -> Q-00013539,...res59: Any = 20L6SC4G00\nres60: Any = Q-00024173\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=7","http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=8"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1544408239264_-947476399","id":"20181206-034434_98546566","dateCreated":"2018-12-10T02:17:19+0000","dateStarted":"2018-12-10T03:02:17+0000","dateFinished":"2018-12-10T03:03:36+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4616"},{"text":"//join product id with description\n val product_join = whole.join(product_description,\"product\").select($\"product_description\",$\"productID\")    //有null description's product.\n // product_join.printSchema()\n val product_detail = product_join.rdd.map(r => (r(1),r(0))).collectAsMap()\n// product_join.filter(\"product_description is null\").show()\n","user":"anonymous","dateUpdated":"2018-12-10T03:44:41+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":6,"editorMode":"ace/mode/scala","fontSize":9,"results":{"0":{"graph":{"mode":"table","height":93,"optionOpen":false}}},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"product_join: org.apache.spark.sql.DataFrame = [product_description: string, productID: double]\nproduct_detail: scala.collection.Map[Any,Any] = Map(12572.0 -> NoteBook TP T480 8G 1TB W10P, 3672.0 -> 2x Gold 5115 (10C 2.4GHz 13.75MB Cache/85W), 32GB(2x16GB, 1Rx4 RDIMM), O/B SATA/NVMe backplane, 4x10Gb LOM, XCC Enterprise, 6938.0 -> NoteBook TP P50 16G 1.25 W10P, 6220.0 -> Workstation TS P320 i5-6500 W10, 12886.0 -> NoteBook TP X380 Yoga 8G 256 W10P, 3331.0 -> ADAPTR TP 45W AC Adapter SlimTip, 5879.0 -> NoteBook TP X270 4G 128 W10P, 2990.0 -> Workstation TS P320 i5-7500 W10, 5538.0 -> NoteBook TP Yoga 370 8G 512 W10P, 5197.0 -> NoteBook TP L570 4G 128 NOOS, 18090.0 -> Desktop LN V410z I5_7400T 8G 1TB W10P, 24038.0 -> NoteBook TP T580 16G 512 W10P, 20952.0 -> NoteBook TP X1 C6 16G 512 W10P, 18404.0 -> Desktop TC M710t I7_7700 8G 256 W10P, 17749.0 -> 4 GB to 8 GB Cache Upgrade, 23697...."}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=17","http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=18"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1544408239265_1557491544","id":"20181206-035821_1799462590","dateCreated":"2018-12-10T02:17:19+0000","dateStarted":"2018-12-10T03:44:41+0000","dateFinished":"2018-12-10T03:45:43+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4617"},{"text":"def computeRmse(model: MatrixFactorizationModel, data: RDD[Rating], n: Long): Double = {\r\n    val predictions: RDD[Rating] = model.predict(data.map(x => (x.user, x.product)))\r\n    val predictionsAndRatings = predictions.map(x => ((x.user, x.product), x.rating))\r\n      .join(data.map(x => ((x.user, x.product), x.rating)))\r\n      .values\r\n    math.sqrt(predictionsAndRatings.map(x => (x._1 - x._2) * (x._1 - x._2)).reduce(_ + _) / n)\r\n  }","user":"anonymous","dateUpdated":"2018-12-10T03:54:03+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"computeRmse: (model: org.apache.spark.mllib.recommendation.MatrixFactorizationModel, data: org.apache.spark.rdd.RDD[org.apache.spark.mllib.recommendation.Rating], n: Long)Double\n"}]},"apps":[],"jobName":"paragraph_1544408239265_1717365908","id":"20181206-071238_122271083","dateCreated":"2018-12-10T02:17:19+0000","dateStarted":"2018-12-10T03:54:03+0000","dateFinished":"2018-12-10T03:54:04+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4618"},{"text":"// split table to test and train set\nval rows: RDD[Row] = table.rdd\n/*\nval splits = table.randomSplit(Array(0.8,0.2),seed = 12345L)\nval (train,test) = (splits(0),splits(1))\nval numTrain = train.count()\nval numTest = test.count()\nprintln(\"Train Data:\" + numTrain + \" Test Data:\" + numTest)\n*/\n","user":"anonymous","dateUpdated":"2018-12-10T03:55:05+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"rows: org.apache.spark.rdd.RDD[org.apache.spark.sql.Row] = MapPartitionsRDD[149] at rdd at <console>:69\n"}]},"apps":[],"jobName":"paragraph_1544408239266_-861415271","id":"20181206-023558_1686975681","dateCreated":"2018-12-10T02:17:19+0000","dateStarted":"2018-12-10T03:55:05+0000","dateFinished":"2018-12-10T03:55:07+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4619"},{"text":"val tableRDD = rows.map(r => Rating(\n  r.getAs[Int](\"userID\"), r.getAs[Int](\"productID\"), r.getAs[Double](\"rating\")\n))\n/*\nval trainRDD = train.rdd.map(r => Rating(\n  r.getAs[Int](\"userID\"), r.getAs[Int](\"productID\"), r.getAs[Double](\"rating\")\n))\n\nval testRDD = test.rdd.map(r => Rating(\n  r.getAs[Int](\"userID\"), r.getAs[Int](\"productID\"), r.getAs[Double](\"rating\")\n))\n*/","user":"anonymous","dateUpdated":"2018-12-10T03:55:10+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"tableRDD: org.apache.spark.rdd.RDD[org.apache.spark.mllib.recommendation.Rating] = MapPartitionsRDD[150] at map at <console>:70\n"}]},"apps":[],"jobName":"paragraph_1544408239266_-1582862796","id":"20181206-024943_267374160","dateCreated":"2018-12-10T02:17:19+0000","dateStarted":"2018-12-10T03:55:10+0000","dateFinished":"2018-12-10T03:55:11+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4620"},{"text":"//////// 找出較佳模型參數\n/*\nval ranks = List(8, 12,20)\n    val lambdas = List(0.1, 1.0, 10.0)\n    val alpha = List(1,40)\n    val numIters = List(10, 20)\n    var bestModel: Option[MatrixFactorizationModel] = None\n    var bestValidationRmse = Double.MaxValue\n    var bestRank = 0\n    var bestLambda = -1.0\n    var bestNumIter = -1\n    var bestAlpha = 0\n    for (rank <- ranks; lambda <- lambdas; numIter <- numIters; alpha <- alpha) {\n      val model = ALS.trainImplicit(trainRDD, rank, numIter, lambda, alpha)\n      val validationRmse = computeRmse(model, testRDD, numTest)\n      println(\"RMSE (validation) = \" + validationRmse + \" for the model trained with rank = \"\n        + rank + \n        \", lambda = \" + lambda + \n        \", alpha = \" + alpha + \n        \", and numIter = \" + numIter + \".\")\n      if (validationRmse < bestValidationRmse) {\n        bestModel = Some(model)\n        bestValidationRmse = validationRmse\n        bestRank = rank\n        bestLambda = lambda\n        bestNumIter = numIter\n        bestAlpha = alpha\n      }\n    }\n\n    val testRmse = computeRmse(bestModel.get, testRDD, numTest)\n\n    println(\"The best model was trained with rank = \" + bestRank + \" and lambda = \" + bestLambda\n      + \", and numIter = \" + bestNumIter + \", and its RMSE on the test set is \" + testRmse + \".\")\n\n*/","user":"anonymous","dateUpdated":"2018-12-10T08:57:20+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{"0":{"graph":{"mode":"table","height":454,"optionOpen":false}}},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"import org.apache.spark.rdd.RDD\nranks: List[Int] = List(8, 12, 20)\nlambdas: List[Double] = List(0.1, 1.0, 10.0)\nalpha: List[Int] = List(1, 40)\nnumIters: List[Int] = List(10, 20)\nbestModel: Option[org.apache.spark.mllib.recommendation.MatrixFactorizationModel] = None\nbestValidationRmse: Double = 1.7976931348623157E308\nbestRank: Int = 0\nbestLambda: Double = -1.0\nbestNumIter: Int = -1\nbestAlpha: Int = 0\nRMSE (validation) = 2.847347274799956 for the model trained with rank = 8, lambda = 0.1, alpha = 1, and numIter = 10.\nRMSE (validation) = 2.7560624651707477 for the model trained with rank = 8, lambda = 0.1, alpha = 40, and numIter = 10.\nRMSE (validation) = 2.8466697456857677 for the model trained with rank = 8, lambda = 0.1, alpha = 1, and numIter = 20.\nRMSE (validation) = 2.7591183281554 for the model trained with rank = 8, lambda = 0.1, alpha = 40, and numIter = 20.\nRMSE (validation) = 2.8785340102361974 for the model trained with rank = 8, lambda = 1.0, alpha = 1, and numIter = 10.\nRMSE (validation) = 2.758219738464296 for the model trained with rank = 8, lambda = 1.0, alpha = 40, and numIter = 10.\nRMSE (validation) = 2.8780450803383295 for the model trained with rank = 8, lambda = 1.0, alpha = 1, and numIter = 20.\nRMSE (validation) = 2.7576616549201343 for the model trained with rank = 8, lambda = 1.0, alpha = 40, and numIter = 20.\nRMSE (validation) = 2.902682359469255 for the model trained with rank = 8, lambda = 10.0, alpha = 1, and numIter = 10.\nRMSE (validation) = 2.777477831463707 for the model trained with rank = 8, lambda = 10.0, alpha = 40, and numIter = 10.\nRMSE (validation) = 2.9026823594703015 for the model trained with rank = 8, lambda = 10.0, alpha = 1, and numIter = 20.\nRMSE (validation) = 2.7770643417427427 for the model trained with rank = 8, lambda = 10.0, alpha = 40, and numIter = 20.\nRMSE (validation) = 2.8455561110884453 for the model trained with rank = 12, lambda = 0.1, alpha = 1, and numIter = 10.\nRMSE (validation) = 2.7575965823067365 for the model trained with rank = 12, lambda = 0.1, alpha = 40, and numIter = 10.\nRMSE (validation) = 2.843354415392529 for the model trained with rank = 12, lambda = 0.1, alpha = 1, and numIter = 20.\nRMSE (validation) = 2.757702880231383 for the model trained with rank = 12, lambda = 0.1, alpha = 40, and numIter = 20.\nRMSE (validation) = 2.8769029808008164 for the model trained with rank = 12, lambda = 1.0, alpha = 1, and numIter = 10.\nRMSE (validation) = 2.7572147379353367 for the model trained with rank = 12, lambda = 1.0, alpha = 40, and numIter = 10.\nRMSE (validation) = 2.8768752097539 for the model trained with rank = 12, lambda = 1.0, alpha = 1, and numIter = 20.\nRMSE (validation) = 2.7550424895336207 for the model trained with rank = 12, lambda = 1.0, alpha = 40, and numIter = 20.\nRMSE (validation) = 2.9026823594675593 for the model trained with rank = 12, lambda = 10.0, alpha = 1, and numIter = 10.\nRMSE (validation) = 2.776787661754127 for the model trained with rank = 12, lambda = 10.0, alpha = 40, and numIter = 10.\nRMSE (validation) = 2.902682359470278 for the model trained with rank = 12, lambda = 10.0, alpha = 1, and numIter = 20.\nRMSE (validation) = 2.7757226289503696 for the model trained with rank = 12, lambda = 10.0, alpha = 40, and numIter = 20.\nRMSE (validation) = 2.842629763871692 for the model trained with rank = 20, lambda = 0.1, alpha = 1, and numIter = 10.\nRMSE (validation) = 2.760989182851731 for the model trained with rank = 20, lambda = 0.1, alpha = 40, and numIter = 10.\nRMSE (validation) = 2.841440644009583 for the model trained with rank = 20, lambda = 0.1, alpha = 1, and numIter = 20.\norg.apache.spark.SparkException: Job 1386 cancelled part of cancelled job group zeppelin-2DZ92S39F-20181206-064537_1456665003\n  at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1803)\n  at org.apache.spark.scheduler.DAGScheduler.handleJobCancellation(DAGScheduler.scala:1738)\n  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleJobGroupCancelled$1.apply$mcVI$sp(DAGScheduler.scala:851)\n  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleJobGroupCancelled$1.apply(DAGScheduler.scala:851)\n  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleJobGroupCancelled$1.apply(DAGScheduler.scala:851)\n  at scala.collection.mutable.HashSet.foreach(HashSet.scala:78)\n  at org.apache.spark.scheduler.DAGScheduler.handleJobGroupCancelled(DAGScheduler.scala:851)\n  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1993)\n  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1973)\n  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1962)\n  at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n  at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:682)\n  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2034)\n  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2131)\n  at org.apache.spark.rdd.RDD$$anonfun$aggregate$1.apply(RDD.scala:1124)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n  at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\n  at org.apache.spark.rdd.RDD.aggregate(RDD.scala:1117)\n  at org.apache.spark.ml.recommendation.ALS$.computeYtY(ALS.scala:1711)\n  at org.apache.spark.ml.recommendation.ALS$.org$apache$spark$ml$recommendation$ALS$$computeFactors(ALS.scala:1652)\n  at org.apache.spark.ml.recommendation.ALS$$anonfun$train$4.apply(ALS.scala:972)\n  at org.apache.spark.ml.recommendation.ALS$$anonfun$train$4.apply(ALS.scala:969)\n  at scala.collection.immutable.Range.foreach(Range.scala:160)\n  at org.apache.spark.ml.recommendation.ALS$.train(ALS.scala:969)\n  at org.apache.spark.mllib.recommendation.ALS.run(ALS.scala:255)\n  at org.apache.spark.mllib.recommendation.ALS$.trainImplicit(ALS.scala:428)\n  at org.apache.spark.mllib.recommendation.ALS$.trainImplicit(ALS.scala:447)\n  at $$$1741c48faa302f95dea11e2e5d7dddc$$$$w$$anonfun$1$$anonfun$apply$mcVI$sp$1$$anonfun$apply$mcVD$sp$1$$anonfun$apply$mcVI$sp$2.apply$mcVI$sp(<console>:272)\n  at $$$1741c48faa302f95dea11e2e5d7dddc$$$$w$$anonfun$1$$anonfun$apply$mcVI$sp$1$$anonfun$apply$mcVD$sp$1$$anonfun$apply$mcVI$sp$2.apply(<console>:271)\n  at $$$1741c48faa302f95dea11e2e5d7dddc$$$$w$$anonfun$1$$anonfun$apply$mcVI$sp$1$$anonfun$apply$mcVD$sp$1$$anonfun$apply$mcVI$sp$2.apply(<console>:271)\n  at scala.collection.immutable.List.foreach(List.scala:381)\n  at $$$1741c48faa302f95dea11e2e5d7dddc$$$$w$$anonfun$1$$anonfun$apply$mcVI$sp$1$$anonfun$apply$mcVD$sp$1.apply$mcVI$sp(<console>:271)\n  at $$$1741c48faa302f95dea11e2e5d7dddc$$$$w$$anonfun$1$$anonfun$apply$mcVI$sp$1$$anonfun$apply$mcVD$sp$1.apply(<console>:271)\n  at $$$1741c48faa302f95dea11e2e5d7dddc$$$$w$$anonfun$1$$anonfun$apply$mcVI$sp$1$$anonfun$apply$mcVD$sp$1.apply(<console>:271)\n  at scala.collection.immutable.List.foreach(List.scala:381)\n  at $$$1741c48faa302f95dea11e2e5d7dddc$$$$w$$anonfun$1$$anonfun$apply$mcVI$sp$1.apply$mcVD$sp(<console>:271)\n  at $$$1741c48faa302f95dea11e2e5d7dddc$$$$w$$anonfun$1$$anonfun$apply$mcVI$sp$1.apply(<console>:271)\n  at $$$1741c48faa302f95dea11e2e5d7dddc$$$$w$$anonfun$1$$anonfun$apply$mcVI$sp$1.apply(<console>:271)\n  at scala.collection.immutable.List.foreach(List.scala:381)\n  at $anonfun$1.apply$mcVI$sp(<console>:271)\n  at $anonfun$1.apply(<console>:271)\n  at $anonfun$1.apply(<console>:271)\n  at scala.collection.immutable.List.foreach(List.scala:381)\n  ... 96 elided\n"}]},"apps":[],"jobName":"paragraph_1544408239268_1977703924","id":"20181206-064537_1456665003","dateCreated":"2018-12-10T02:17:19+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:4621"},{"text":"// feedback for RMSE\n// rank larger有幫助, 但12,20沒有表現比8,12好; rank=12 better than rank=8\n// lambda should not be 10; lambda 1.0 better than 0.1.\n// alpha 40 better than 1.\n/*\n循环次数iter，这个设置的越大肯定是越精确，但是设置的越大也就意味着越耗时；\nrank ，特征向量纬度，这个设置就要看了，如果太小拟合的就会不够，误差就很大；如果设置很大，就会导致模型大泛化能力较差；所以就需要自己把握一个度了，一般情况下10～100都是可以的；\nlambda也是和rank一样的，如果设置很大就可以防止过拟合问题，如果设置很小，其实可以理解为直接设置为0，那么就不会有防止过拟合的功能了；怎么设置呢？可以从0.0001 ，0.0003，0.001，0.003，0.01，0.03，0.1，0.3，1，3，10这样每次大概3倍的设置，先大概看下哪个值效果比较好，然后在那个比较好的值（比如说0.01）前后再设置一个范围，比如（0.003，0.3）之间，间隔设置小点，即0.003，0.005，0.007，0.009，0.011，，，，。当然，如果机器性能够好，而且你够时间，可以直接设置从0到100，间隔很小，然后一组参数一组的试试也是可以的。\n*/\n","user":"anonymous","dateUpdated":"2018-12-10T05:12:40+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1544408239269_-1993073633","id":"20181206-092423_536583109","dateCreated":"2018-12-10T02:17:19+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:4622"},{"text":"\nval rank = 12\nval numIterations = 20\nval alpha = 40\nval lambda = 0.00003\n// val block = -1\nval seed = 1222L\nval implicitPrefs = true\nval model = new ALS().\nsetIterations(numIterations).\n// setBlocks(block).\nsetAlpha(alpha).\nsetLambda(lambda).\nsetRank(rank).\nsetSeed(seed).\nsetImplicitPrefs(implicitPrefs).\nrun(tableRDD)","user":"anonymous","dateUpdated":"2018-12-10T06:08:14+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"rank: Int = 12\nnumIterations: Int = 20\nalpha: Double = 0.01\nlambda: Double = 3.0E-5\nseed: Long = 1222\nimplicitPrefs: Boolean = true\nmodel: org.apache.spark.mllib.recommendation.MatrixFactorizationModel = org.apache.spark.mllib.recommendation.MatrixFactorizationModel@6afe1889\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=277","http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=278","http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=279","http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=280","http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=281","http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=282","http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=283","http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=284","http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=285","http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=286","http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=287","http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=288","http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=289","http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=290","http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=291","http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=292","http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=293","http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=294","http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=295","http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=296","http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=297","http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=298","http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=299","http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=300","http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=301","http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=302","http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=303","http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=304","http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=305","http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=306","http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=307","http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=308","http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=309","http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=310","http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=311","http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=312","http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=313","http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=314","http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=315","http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=316","http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=317","http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=318","http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=319","http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=320","http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=321","http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=322","http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=323","http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=324"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1544408239270_-201318632","id":"20181206-015929_494305696","dateCreated":"2018-12-10T02:17:19+0000","dateStarted":"2018-12-10T05:38:25+0000","dateFinished":"2018-12-10T05:53:42+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4623"},{"text":"model.userFeatures.take(5)\nmodel.productFeatures.take(5)\n/*\nuserFactor & productFactor 值介於-1~1之間較佳。\n*/","user":"anonymous","dateUpdated":"2018-12-10T05:54:12+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"res191: Array[(Int, Array[Double])] = Array((0,Array(0.3480719327926636, 0.9355241060256958, 0.1978924572467804, 0.920537531375885, 0.2886412441730499, -0.003820783458650112, 0.37188848853111267, 0.4841785728931427, -0.4169345796108246, -0.3345091938972473, 0.2955411672592163, -0.38206878304481506)), (100,Array(6.779922962188721, -4.117086410522461, -0.19105717539787292, -8.754883766174316, 5.598392009735107, 1.852394700050354, 8.334810256958008, -1.94929838180542, 3.068195343017578, -2.1942033767700195, -4.483232021331787, -3.704008102416992)), (200,Array(0.7778744101524353, 2.24228572845459, 0.5024698376655579, 2.1682183742523193, 0.7504076361656189, 0.011057809926569462, 0.7238171696662903, 1.132805585861206, -0.9119490385055542, -0.7909121513366699, 0.7909502983093262, -0.8578615188...res192: Array[(Int, Array[Double])] = Array((0,Array(0.03737450763583183, -0.10056473314762115, -0.009848135523498058, 0.01937464438378811, 0.06023487448692322, 0.08661264926195145, -0.01976655051112175, 0.04746692627668381, -0.013695603236556053, 0.01871035061776638, -0.06986838579177856, 0.011804272420704365)), (100,Array(0.020915798842906952, 0.0016412453260272741, 0.005663939751684666, -0.006537595763802528, 0.01679283380508423, -0.0021301705855876207, 0.016123894602060318, -0.014474301598966122, -0.0011096649104729295, 0.0012022856390103698, -0.012829573825001717, -0.006835241802036762)), (200,Array(0.0028775124810636044, -0.005083408206701279, -0.004559429828077555, 0.0011260508326813579, 0.004115510731935501, 0.003116656793281436, 3.313675697427243E-4, 0.0029917340725660324, 0.01..."}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=325","http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=326"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1544414503101_-1906800951","id":"20181210-040143_1902627218","dateCreated":"2018-12-10T04:01:43+0000","dateStarted":"2018-12-10T05:54:12+0000","dateFinished":"2018-12-10T05:54:14+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4624"},{"text":"//推薦K項產品\nmodel.recommendProducts(54,5)\n// 用戶對於某產品的預測評分\nmodel.predict(54,54)","user":"anonymous","dateUpdated":"2018-12-10T10:38:54+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"res421: Array[org.apache.spark.mllib.recommendation.Rating] = Array(Rating(54,5,2.38970627678863), Rating(54,177,2.079386002318782), Rating(54,85,1.9744379525183933), Rating(54,3,1.859620967452589), Rating(54,4,1.7740369829390978))\nres423: Double = -0.34194837084067214\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=464","http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=465","http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=466","http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=467"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1544420038551_1590260329","id":"20181210-053358_1993935820","dateCreated":"2018-12-10T05:33:58+0000","dateStarted":"2018-12-10T10:38:44+0000","dateFinished":"2018-12-10T10:38:51+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4625"},{"text":"model.predict(10726,23877)","user":"anonymous","dateUpdated":"2018-12-10T10:52:10+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"res447: Double = 0.8096668118725175\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=485","http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=486"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1544435758751_-123472376","id":"20181210-095558_1153138985","dateCreated":"2018-12-10T09:55:58+0000","dateStarted":"2018-12-10T10:52:10+0000","dateFinished":"2018-12-10T10:52:11+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4626"},{"text":"whole.filter($\"productID\" === 9879).sort($\"rating\".desc).show","user":"anonymous","dateUpdated":"2018-12-10T10:18:46+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+----------+----------+------+-------+---------+\n|      user|   product|rating| userID|productID|\n+----------+----------+------+-------+---------+\n|Q-00067764|10MQS3UB00| 500.0|23293.0|   9879.0|\n|Q-00026769|10MQS3UB00| 300.0| 9200.0|   9879.0|\n+----------+----------+------+-------+---------+\n\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=463"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1544437025935_631899498","id":"20181210-101705_1050526412","dateCreated":"2018-12-10T10:17:05+0000","dateStarted":"2018-12-10T10:18:36+0000","dateFinished":"2018-12-10T10:19:22+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4627"},{"text":"whole.filter($\"userID\" === 3).sort($\"rating\".asc).show","user":"anonymous","dateUpdated":"2018-12-10T10:47:36+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+----------+----------+------+------+---------+\n|      user|   product|rating|userID|productID|\n+----------+----------+------+------+---------+\n|Q-00055241|4XB0N10300|1500.0|   3.0|    305.0|\n|Q-00055241|4X40E77325|1500.0|   3.0|     46.0|\n|Q-00055241|40AC0135EU|1500.0|   3.0|      9.0|\n|Q-00055241|4X40N18008|1500.0|   3.0|     89.0|\n|Q-00055241|   0B47374|1500.0|   3.0|    121.0|\n|Q-00055241|4XB0N71413|1500.0|   3.0|   3140.0|\n|Q-00055241|4XA0M84911|1500.0|   3.0|   1016.0|\n|Q-00055241|4X30H56886|1500.0|   3.0|    189.0|\n|Q-00055241|   0B47036|1500.0|   3.0|    134.0|\n|Q-00055241|4X60K92692|1500.0|   3.0|   8112.0|\n|Q-00055241|   41N3040|1500.0|   3.0|   1973.0|\n|Q-00055241|   0B47092|1500.0|   3.0|    833.0|\n|Q-00055241|4X60M97030|1500.0|   3.0|   2830.0|\n|Q-00055241|4X70N24889|1500.0|   3.0|     67.0|\n|Q-00055241|   0A65633|1500.0|   3.0|  10220.0|\n|Q-00055241|   57Y4393|1500.0|   3.0|    117.0|\n|Q-00055241|GX20M08198|1500.0|   3.0|   1454.0|\n|Q-00055241|4XA0N06918|1500.0|   3.0|   1781.0|\n|Q-00055241|40AB0065EU|1500.0|   3.0|    725.0|\n|Q-00055241|4X40H01536|1500.0|   3.0|   8329.0|\n+----------+----------+------+------+---------+\nonly showing top 20 rows\n\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=482"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1544438739213_388889636","id":"20181210-104539_1692583017","dateCreated":"2018-12-10T10:45:39+0000","dateStarted":"2018-12-10T10:47:22+0000","dateFinished":"2018-12-10T10:47:28+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4628"},{"text":"whole.filter($\"userID\" === 3).sort($\"rating\".desc).show","user":"anonymous","dateUpdated":"2018-12-10T10:45:27+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+----------+----------+------+------+---------+\n|      user|   product|rating|userID|productID|\n+----------+----------+------+------+---------+\n|Q-00055241|   0B47167|3000.0|   3.0|   1123.0|\n|Q-00055241|   0B47089|3000.0|   3.0|    106.0|\n|Q-00055241|4Z10G95467|3000.0|   3.0|   9933.0|\n|Q-00055241|   0A36302|3000.0|   3.0|    381.0|\n|Q-00055241|4Z10G95468|3000.0|   3.0|   9081.0|\n|Q-00055241|4X80K32539|3000.0|   3.0|    556.0|\n|Q-00055241|   0A36304|1500.0|   3.0|   2053.0|\n|Q-00055241|4XD0J65080|1500.0|   3.0|   6224.0|\n|Q-00055241| 888016697|1500.0|   3.0|  12215.0|\n|Q-00055241|4XB0P01014|1500.0|   3.0|    557.0|\n|Q-00055241|4X60M97030|1500.0|   3.0|   2830.0|\n|Q-00055241|4XA0M84911|1500.0|   3.0|   1016.0|\n|Q-00055241|   43R1990|1500.0|   3.0|   1023.0|\n|Q-00055241|4X70K09920|1500.0|   3.0|   1497.0|\n|Q-00055241|4X50L08495|1500.0|   3.0|    344.0|\n|Q-00055241|4XA0N06917|1500.0|   3.0|    327.0|\n|Q-00055241|40AB0065EU|1500.0|   3.0|    725.0|\n|Q-00055241|4X40H01536|1500.0|   3.0|   8329.0|\n|Q-00055241|GX70K42907|1500.0|   3.0|   9575.0|\n|Q-00055241|   0A61768|1500.0|   3.0|   1122.0|\n+----------+----------+------+------+---------+\nonly showing top 20 rows\n\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=480"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1544425589713_-1690276732","id":"20181210-070629_1590507262","dateCreated":"2018-12-10T07:06:29+0000","dateStarted":"2018-12-10T10:45:27+0000","dateFinished":"2018-12-10T10:45:44+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4629"},{"text":"//model.recommendProducts(0,5)\n//model.recommendProducts(1,5)\nmodel.recommendProducts(22200,11965)\n/*\n Array(Rating(3,54,1.9176265876011722), Rating(3,164,1.3943056274111554), Rating(3,786,1.3255668163647567), Rating(3,906,1.2113142887277017), Rating(3,83,1.1953481554087924))\nres300: Any = CASE_BO Professional Backpack\nres301: Any = 65w  DC travel adaptor\nres302: Any = LICENSEKEY Absolute DDSPRO-F-V1-36\nres303: Any = LICENSEKEY Absolute DDSPRO-F-V1-12\nres304: Any = ADAPTR TP 45W AC Adapter SlimTip\n*/\n//model.recommendProducts(5,5)\n\n//product_detail(54)\n//product_detail(164)\n//product_detail(786)\nproduct_detail(906)\nproduct_detail(83)\n\n// user 1 購買紀錄\nval productForUser = tableRDD.keyBy(_.user).lookup(3)\n\n// user 評分最高的10項產品\nproductForUser.sortBy(-_.rating).take(10).map(table => (product_detail(table.product), table.rating)).foreach(println)\n/*\nproductForUser:\n(TAB ACC_BO Pen Pro X1 Yoga,3000.0)\n(BATTERY ThinkPad Battery 70,3000.0)\n(CABLE_BO mini DisplayPort to HDMI,3000.0)\n(ACC_PARTS Lenovo PF for Helix (Gen 2),3000.0)\n(ACC_PARTS Lenovo Anti-Glare SP-Helix,3000.0)\n(MOUSE       Wireless Mouse Silver-BB,3000.0)\n(CASE_BO ThinkPad Sleeve 13\"\",1500.0)\n(HDD_BO TP 512GB PCIe x4 SSD,1500.0)\n(MEMORY_BO 8GB DDR4 2400MHz SoDIMM,1500.0)\n(BATT_BO Thinkpad Battery 57+,1500.0)\n*/","user":"anonymous","dateUpdated":"2018-12-10T09:55:52+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"res335: Array[org.apache.spark.mllib.recommendation.Rating] = Array(Rating(3,54,1.9176265876011722), Rating(3,164,1.3943056274111554), Rating(3,786,1.3255668163647567), Rating(3,906,1.2113142887277017), Rating(3,83,1.1953481554087924))\nres338: Any = CASE_BO Professional Backpack\nres339: Any = 65w  DC travel adaptor\nres340: Any = LICENSEKEY Absolute DDSPRO-F-V1-36\nres341: Any = LICENSEKEY Absolute DDSPRO-F-V1-12\nres342: Any = ADAPTR TP 45W AC Adapter SlimTip\nproductForUser: Seq[org.apache.spark.mllib.recommendation.Rating] = WrappedArray(Rating(3,89,1500.0), Rating(3,10989,1500.0), Rating(3,15,1500.0), Rating(3,237,1500.0), Rating(3,1593,1500.0), Rating(3,5936,1500.0), Rating(3,345,1500.0), Rating(3,6224,1500.0), Rating(3,3235,1500.0), Rating(3,1,1500.0), Rating(3,795,1500.0), Rating(3,1787,1500.0), Rating(3,2159,1500.0), Rating(3,9588,1500.0), Rating(3,471,1500.0), Rating(3,997,1500.0), Rating(3,557,1500.0), Rating(3,6684,1500.0), Rating(3,646,1500.0), Rating(3,344,1500.0), Rating(3,7766,1500.0), Rating(3,215,1500.0), Rating(3,43,1500.0), Rating(3,18,1500.0), Rating(3,7229,1500.0), Rating(3,1016,1500.0), Rating(3,749,1500.0), Rating(3,208,1500.0), Rating(3,2036,1500.0), Rating(3,11532,1500.0), Rating(3,1820,1500.0), Rating(3,3096,1500.0), ...(TAB ACC_BO Pen Pro X1 Yoga,3000.0)\n(BATTERY ThinkPad Battery 70,3000.0)\n(CABLE_BO mini DisplayPort to HDMI,3000.0)\n(ACC_PARTS Lenovo PF for Helix (Gen 2),3000.0)\n(ACC_PARTS Lenovo Anti-Glare SP-Helix,3000.0)\n(MOUSE       Wireless Mouse Silver-BB,3000.0)\n(CASE_BO ThinkPad Sleeve 13\"\",1500.0)\n(HDD_BO TP 512GB PCIe x4 SSD,1500.0)\n(MEMORY_BO 8GB DDR4 2400MHz SoDIMM,1500.0)\n(BATT_BO Thinkpad Battery 57+,1500.0)\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=374","http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=375","http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=376"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1544421842794_-1289451231","id":"20181210-060402_687163668","dateCreated":"2018-12-10T06:04:02+0000","dateStarted":"2018-12-10T07:01:20+0000","dateFinished":"2018-12-10T07:01:55+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4630"},{"text":"// 选定id为24208的產品\r\nval itemId = 1123\r\n// 获取该物品的隐因子向量\r\nval itemFactor = model.productFeatures.lookup(itemId).head\r\n// 将该向量转换为jblas矩阵类型\r\nval itemVector = new DoubleMatrix(itemFactor)","user":"anonymous","dateUpdated":"2018-12-10T07:10:58+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"itemId: Int = 1123\nitemFactor: Array[Double] = Array(-0.0015756748616695404, -6.844791350886226E-4, -0.001058591646142304, 0.003970747347921133, -4.008238320238888E-4, -1.978883119591046E-5, 0.0015533347614109516, -0.00530591607093811, 0.006682850420475006, -0.004394040908664465, -0.0167092178016901, -0.00851131696254015)\nitemVector: org.jblas.DoubleMatrix = [-0.0015756748616695404; -6.844791350886226E-4; -0.001058591646142304; 0.003970747347921133; -4.008238320238888E-4; -1.978883119591046E-5; 0.0015533347614109516; -0.00530591607093811; 0.006682850420475006; -0.004394040908664465; -0.0167092178016901; -0.00851131696254015]\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=378"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1544425850179_1208124638","id":"20181210-071050_1796274509","dateCreated":"2018-12-10T07:10:50+0000","dateStarted":"2018-12-10T07:10:58+0000","dateFinished":"2018-12-10T07:10:59+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4631"},{"text":"// 打印產品ID:24208的產品description\r\nprintln(product_detail(1123))\r\n// 获取和產品ID:24208最相似的11個產品(含自己)\r\nval sortedSims2 = sims.top(10)(Ordering.by[(Int, Double), Double] { case (id, similarity) => similarity })\r\n// 再打印和產品ID:24208最相似的10項產品\r\nsortedSims2.slice(1, 11).map{ case (id, sim) => (product_detail(id), sim) }.mkString(\"\\n\")","user":"anonymous","dateUpdated":"2018-12-10T07:11:52+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"MOUSE       Wireless Mouse Silver-BB\nsortedSims2: Array[(Int, Double)] = Array((24208,1.0000000000000002), (9419,0.997440223350829), (8249,0.9762538992089129), (11821,0.9762538992089129), (1387,0.9758027109237642), (11230,0.9752003589889842), (2641,0.9743952742994763), (1793,0.9735424450964276), (3580,0.9708353268142326), (1701,0.9682176450990284))\nres360: String =\n(Desktop TC M710q I37100T 4G 500 W10P,0.997440223350829)\n(Desktop TC M600 4G 32G W10 IOT,0.9762538992089129)\n(Desktop TC M600 4G 32G W10 IOT,0.9762538992089129)\n(Desktop TC M710s I57400 8G N W10P,0.9758027109237642)\n(NoteBook TP X1 C5 16G 1TB W10P,0.9752003589889842)\n(Workstation TS ThinkStation P320 Tiny i7,0.9743952742994763)\n(Tablet IP MIIX 320-10ICR Z8350 4G 64 10P,0.9735424450964276)\n(NoteBook TP P52s 8G 256 W10P,0.9708353268142326)\n(Workstation TS P320 i7-7700K W10,0.9682176450990284)\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=379"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1544425905212_-1949903857","id":"20181210-071145_1862417500","dateCreated":"2018-12-10T07:11:45+0000","dateStarted":"2018-12-10T07:11:52+0000","dateFinished":"2018-12-10T07:11:59+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4632"},{"text":"//存回s3但極慢\n\nmodel.recommendProductsForUsers(5).flatMap(x => {\n      val user = x._1.toString\n      val rat = x._2\n\n      var res = List[(String,String)]()\n      for( r <- rat){\n        res=res:+(user,r.product+\",\"+r.rating)\n      }\n      res\n    }).saveAsTextFile(\"s3://input-smart-find/rec.csv\")","user":"anonymous","dateUpdated":"2018-12-10T08:34:29+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"res182: org.apache.spark.rdd.RDD[(String, String)] = MapPartitionsRDD[2318] at flatMap at <console>:87\n"}]},"apps":[],"jobName":"paragraph_1544419264376_1504370082","id":"20181210-052104_233449840","dateCreated":"2018-12-10T05:21:04+0000","dateStarted":"2018-12-10T05:35:57+0000","dateFinished":"2018-12-10T05:35:58+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4633"},{"text":"val someUsers = tableRDD.map(_.user).distinct().take(10)\r\n\r\nval someRecommendations =\r\n\r\nsomeUsers.map(userID => model.recommendProducts(userID, 5))\r\n\r\nsomeRecommendations.map(\r\n\r\nrecs => recs.head.user + \" -> \" + recs.map(_.product).mkString(\", \")\r\n\r\n).foreach(println)","user":"anonymous","dateUpdated":"2018-12-10T08:51:00+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"someUsers: Array[Int] = Array(25400, 22200, 9200, 11600, 600, 6400, 24200, 29800, 26000, 30600)\nsomeRecommendations: Array[Array[org.apache.spark.mllib.recommendation.Rating]] = Array(Array(Rating(25400,18,0.04784939703359871), Rating(25400,86,0.04428007478071671), Rating(25400,0,0.043819056238785126), Rating(25400,8,0.04207738273571941), Rating(25400,153,0.04062936427893943)), Array(Rating(22200,4,0.0), Rating(22200,104,0.0), Rating(22200,204,0.0), Rating(22200,304,0.0), Rating(22200,404,0.0)), Array(Rating(9200,177,2.1308715076556015E-26), Rating(9200,48,1.630090774959183E-26), Rating(9200,266,1.580920444743113E-26), Rating(9200,156,1.5421084864023762E-26), Rating(9200,303,1.5154736175323022E-26)), Array(Rating(11600,0,0.6593956622586183), Rating(11600,2,0.2965836935854327), Rating(11600,4,0.28318715394313315), Rating(11600,5,0.2306239153701291), Rating(11600,18,0.21271437801532...25400 -> 18, 86, 0, 8, 153\n22200 -> 4, 104, 204, 304, 404\n9200 -> 177, 48, 266, 156, 303\n11600 -> 0, 2, 4, 5, 18\n600 -> 28, 16, 8, 39, 177\n6400 -> 0, 4, 18, 39, 85\n24200 -> 3, 11, 23, 24, 32\n29800 -> 3, 17, 24, 32, 29\n26000 -> 17, 29, 24, 104, 32\n30600 -> 1, 6, 9, 13, 20\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=413","http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=414","http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=415","http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=416","http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=417","http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=418","http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=419","http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=420","http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=421","http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=422","http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=423","http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=424","http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=425","http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=426","http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=427","http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=428","http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=429","http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=430","http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=431","http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=432","http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=433"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1544426595236_1896450148","id":"20181210-072315_2045505939","dateCreated":"2018-12-10T07:23:15+0000","dateStarted":"2018-12-10T08:51:00+0000","dateFinished":"2018-12-10T08:52:20+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4634"},{"text":"// 特定userIDwjo \nfor (userID <- Array(1,3,5,0)) {\n     val topKRecs = model.recommendProducts(userID,5)\n    println(topKRecs.mkString(\"\\n\"))\n    }","user":"anonymous","dateUpdated":"2018-12-10T08:52:26+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"<console>:91: error: value toArray is not a member of org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]\n       for (userID <- userIDtest.toArray ) {\n                                 ^\n"}]},"apps":[],"jobName":"paragraph_1544408239276_-321416106","id":"20181207-085839_1430244179","dateCreated":"2018-12-10T02:17:19+0000","dateStarted":"2018-12-10T08:48:45+0000","dateFinished":"2018-12-10T08:48:45+0000","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:4635"},{"text":"// 推薦某用戶top5產品\n//model.recommendProducts(userID,5)\n\n\n\n\n\n// 推薦所有用戶10項產品\n//val ProductsForUsers = model.recommendProductsForUsers(10)\n//ProductsForUsers.collect().foreach(println)\n//ProductsForUsers.take(10).foreach(println)\n//println(ProductsForUsers.first())\n\n//val df = ProductsForUsers.map(Row.fromSeq(_)).toDF()\n\n////\n//model.recommendUsersForProduct(10)\n//model.recommendForAllItems(10) \n// recommendUsersForProducts\n","user":"anonymous","dateUpdated":"2018-12-10T06:30:27+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"productForUser: Seq[org.apache.spark.mllib.recommendation.Rating] = WrappedArray(Rating(7696,3,500.0), Rating(7696,21270,500.0), Rating(7696,23,500.0), Rating(7696,17452,500.0))\n(40A90090UK,500.0)\n(4Z90Q25510,500.0)\n(40A70045UK,500.0)\n(4Z50Q25509,500.0)\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=352"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1544408239277_-1216373368","id":"20181206-021319_1902964286","dateCreated":"2018-12-10T02:17:19+0000","dateStarted":"2018-12-10T06:27:49+0000","dateFinished":"2018-12-10T06:28:13+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4636"},{"text":"// 计算產品24208与其他產品的相似度\r\nval sims = model.productFeatures.map{ case (id, factor) => \r\n    val factorVector = new DoubleMatrix(factor)\r\n    val sim = cosineSimilarity(factorVector, itemVector)\r\n    (id, sim)\r\n}\r\n// 获取与电影24208最相似的5個產品\r\nval sortedSims = sims.top(5)(Ordering.by[(Int, Double), Double] { case (id, similarity) => similarity })\r\n// 打印结果\r\nprintln(sortedSims.mkString(\"\\n\"))\r\n\r\n\r\n//相似物品description驗證\r\nproduct_detail(24208)\r\nproduct_detail(9419)\r\nproduct_detail(8249)\r\nproduct_detail(11821)\r\nproduct_detail(1387)","user":"anonymous","dateUpdated":"2018-12-10T06:19:43+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"sims: org.apache.spark.rdd.RDD[(Int, Double)] = MapPartitionsRDD[2787] at map at <console>:95\nsortedSims: Array[(Int, Double)] = Array((24208,1.0000000000000002), (9419,0.997440223350829), (8249,0.9762538992089129), (11821,0.9762538992089129), (1387,0.9758027109237642))\n(24208,1.0000000000000002)\n(9419,0.997440223350829)\n(8249,0.9762538992089129)\n(11821,0.9762538992089129)\n(1387,0.9758027109237642)\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://ip-172-31-7-162.ec2.internal:4040/jobs/job?id=349"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1544408239279_824371385","id":"20181207-052635_1181495816","dateCreated":"2018-12-10T02:17:19+0000","dateStarted":"2018-12-10T06:12:21+0000","dateFinished":"2018-12-10T06:12:28+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4637"},{"text":"ProductsForUsers.map(table => (product_name(table.product), table.rating)).foreach(println)","user":"anonymous","dateUpdated":"2018-12-10T02:17:19+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"MapPartitionsRDD[661] at mapValues at <console>:75\n"}]},"apps":[],"jobName":"paragraph_1544408239280_1528841014","id":"20181207-024506_755598606","dateCreated":"2018-12-10T02:17:19+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:4638"},{"text":"//MAP evaluation\n/* Compute recommendations for all users */\nval itemFactors = model.productFeatures.map { case (id, factor) => factor }.collect()\nval itemMatrix = new DoubleMatrix(itemFactors)\nprintln(itemMatrix.rows, itemMatrix.columns)\n","user":"anonymous","dateUpdated":"2018-12-10T02:17:19+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"itemFactors: Array[Array[Double]] = Array(Array(0.01026960276067257, -0.4746765196323395, -0.05678558722138405, -0.033754173666238785, 0.21270030736923218, 0.2455088049173355, 0.3098829686641693, 0.0991937592625618, -0.16950370371341705, 0.01789691671729088, -0.2586459219455719, 0.14778737723827362), Array(0.02894260175526142, -0.022552132606506348, 0.11445462703704834, -0.015370170585811138, 0.030125999823212624, -0.012784705497324467, 0.13804937899112701, -0.08350232243537903, 0.020371969789266586, -0.005294233560562134, -0.05192679166793823, 0.026053179055452347), Array(-0.019226964563131332, -0.01767345890402794, -0.05895422399044037, 0.020856620743870735, 0.010196109302341938, -0.038020260632038116, 0.06418273597955704, 0.0029479111544787884, -0.014139467850327492, -0.0302533786743...itemMatrix: org.jblas.DoubleMatrix = [0.01026960276067257, -0.4746765196323395, -0.05678558722138405, -0.033754173666238785, 0.21270030736923218, 0.2455088049173355, 0.3098829686641693, 0.0991937592625618, -0.16950370371341705, 0.01789691671729088, -0.2586459219455719, 0.14778737723827362; 0.02894260175526142, -0.022552132606506348, 0.11445462703704834, -0.015370170585811138, 0.030125999823212624, -0.012784705497324467, 0.13804937899112701, -0.08350232243537903, 0.020371969789266586, -0.005294233560562134, -0.05192679166793823, 0.026053179055452347; -0.019226964563131332, -0.01767345890402794, -0.05895422399044037, 0.020856620743870735, 0.010196109302341938, -0.038020260632038116, 0.06418273597955704, 0.0029479111544787884, -0.014139467850327492, -0.030253378674387932, -0.12717337906360...(24209,12)\n"}]},"apps":[],"jobName":"paragraph_1544408239280_-307519394","id":"20181207-053736_887108495","dateCreated":"2018-12-10T02:17:19+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:4639"},{"text":"val imBroadcast = sc.broadcast(itemMatrix)\nval allRecs = model.userFeatures.map{ case (userId, array) => \n  val userVector = new DoubleMatrix(array)\n  val scores = imBroadcast.value.mmul(userVector)\n  val sortedWithId = scores.data.zipWithIndex.sortBy(-_._1)\n  val recommendedIds = sortedWithId.map(_._2 + 1).toSeq\n  (userId, recommendedIds)\n}\n","user":"anonymous","dateUpdated":"2018-12-10T02:17:19+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"imBroadcast: org.apache.spark.broadcast.Broadcast[org.jblas.DoubleMatrix] = Broadcast(312)\nallRecs: org.apache.spark.rdd.RDD[(Int, Seq[Int])] = MapPartitionsRDD[1258] at map at <console>:103\n"}]},"apps":[],"jobName":"paragraph_1544408239281_-1252367384","id":"20181207-053830_562477089","dateCreated":"2018-12-10T02:17:19+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:4640"},{"text":"val test = allRecs.take(3)\ntest.toDF().show()","user":"anonymous","dateUpdated":"2018-12-10T02:17:19+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"test: Array[(Int, Seq[Int])] = Array((0,WrappedArray(5818, 3416, 20581, 17199, 5576, 1, 15744, 978, 16466, 2679, 8246, 19373, 494, 2921, 5334, 1465, 8001, 18421, 15746, 22530, 5145, 9762, 736, 8003, 9455, 21554, 9215, 6793, 13810, 2924, 6552, 7046, 7520, 7280, 6801, 16963, 11, 11394, 5106, 20345, 20589, 16960, 13331, 23979, 9747, 18413, 14542, 8737, 18407, 8010, 1713, 6321, 10673, 6315, 23015, 8980, 16481, 2203, 10683, 19869, 5342, 15757, 8738, 8496, 13338, 7043, 264, 15276, 23020, 13335, 15025, 4867, 7529, 23262, 2209, 4871, 17449, 15026, 8494, 22287, 16487, 13572, 18914, 3894, 18655, 11880, 6075, 5835, 5111, 20114, 499, 1959, 12848, 4623, 23016, 7524, 9956, 12859, 18913, 4148, 1483, 13814, 10190, 22529, 19, 12616, 260, 3668, 3904, 16236, 21082, 21813, 4875, 14552, 758, 15523, 1237, 13...<console>:108: error: value toDF is not a member of Array[(Int, Seq[Int])]\n       test.toDF().show()\n            ^\n"}]},"apps":[],"jobName":"paragraph_1544408239282_1428784517","id":"20181207-064933_1264123519","dateCreated":"2018-12-10T02:17:19+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:4641"},{"text":"val userMovies = tableRDD.map{ case Rating(user, product, rating) => (user, product) }.groupBy(_._1)\nimport org.apache.spark.mllib.evaluation.RankingMetrics\nval predictedAndTrueForRanking = allRecs.join(userMovies).map{ case (userId, (predicted, actualWithIds)) => \n  val actual = actualWithIds.map(_._2)\n  (predicted.toArray, actual.toArray)\n}\nval rankingMetrics = new RankingMetrics(predictedAndTrueForRanking)\nprintln(\"Mean Average Precision = \" + rankingMetrics.meanAveragePrecision)\n","user":"anonymous","dateUpdated":"2018-12-10T02:17:19+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"userMovies: org.apache.spark.rdd.RDD[(Int, Iterable[(Int, Int)])] = ShuffledRDD[1261] at groupBy at <console>:78\nimport org.apache.spark.mllib.evaluation.RankingMetrics\npredictedAndTrueForRanking: org.apache.spark.rdd.RDD[(Array[Int], Array[Int])] = MapPartitionsRDD[1265] at map at <console>:108\nrankingMetrics: org.apache.spark.mllib.evaluation.RankingMetrics[Int] = org.apache.spark.mllib.evaluation.RankingMetrics@1620f146\norg.apache.spark.SparkException: Job aborted due to stage failure: Task 23 in stage 4573.0 failed 4 times, most recent failure: Lost task 23.3 in stage 4573.0 (TID 41502, ip-172-31-3-65.ec2.internal, executor 180): ExecutorLostFailure (executor 180 exited caused by one of the running tasks) Reason: Container marked as failed: container_1544146771303_0001_01_000437 on host: ip-172-31-3-65.ec2.internal. Exit status: 50. Diagnostics: Exception from container-launch.\nContainer id: container_1544146771303_0001_01_000437\nExit code: 50\nStack trace: ExitCodeException exitCode=50:\n\tat org.apache.hadoop.util.Shell.runCommand(Shell.java:972)\n\tat org.apache.hadoop.util.Shell.run(Shell.java:869)\n\tat org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:1170)\n\tat org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:235)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:299)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:83)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\n\nContainer exited with a non-zero exit code 50\n\nDriver stacktrace:\n  at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1803)\n  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1791)\n  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1790)\n  at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n  at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n  at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1790)\n  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:871)\n  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:871)\n  at scala.Option.foreach(Option.scala:257)\n  at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:871)\n  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2024)\n  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1973)\n  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1962)\n  at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n  at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:682)\n  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2034)\n  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2131)\n  at org.apache.spark.rdd.RDD$$anonfun$reduce$1.apply(RDD.scala:1035)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n  at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\n  at org.apache.spark.rdd.RDD.reduce(RDD.scala:1017)\n  at org.apache.spark.rdd.DoubleRDDFunctions$$anonfun$stats$1.apply(DoubleRDDFunctions.scala:43)\n  at org.apache.spark.rdd.DoubleRDDFunctions$$anonfun$stats$1.apply(DoubleRDDFunctions.scala:43)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n  at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\n  at org.apache.spark.rdd.DoubleRDDFunctions.stats(DoubleRDDFunctions.scala:42)\n  at org.apache.spark.rdd.DoubleRDDFunctions$$anonfun$mean$1.apply$mcD$sp(DoubleRDDFunctions.scala:48)\n  at org.apache.spark.rdd.DoubleRDDFunctions$$anonfun$mean$1.apply(DoubleRDDFunctions.scala:48)\n  at org.apache.spark.rdd.DoubleRDDFunctions$$anonfun$mean$1.apply(DoubleRDDFunctions.scala:48)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n  at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\n  at org.apache.spark.rdd.DoubleRDDFunctions.mean(DoubleRDDFunctions.scala:47)\n  at org.apache.spark.mllib.evaluation.RankingMetrics.meanAveragePrecision$lzycompute(RankingMetrics.scala:108)\n  at org.apache.spark.mllib.evaluation.RankingMetrics.meanAveragePrecision(RankingMetrics.scala:87)\n  ... 60 elided\n"}]},"apps":[],"jobName":"paragraph_1544408239282_-2032027306","id":"20181207-053905_230491467","dateCreated":"2018-12-10T02:17:19+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:4642"},{"text":"// Evaluation\nval usersProducts = testRDD.map { case Rating(user,product,rating) => (user,product)}\nval predictions = model.predict(usersProducts).map{\n     case Rating(user, product, rating) => ((user, product), rating)\n }\n \nval ratingsAndPredictions = testRDD.map{\n  case Rating(user, product, rating) => ((user, product), rating)\n }.join(predictions)\n","user":"anonymous","dateUpdated":"2018-12-10T02:17:19+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"usersProducts: org.apache.spark.rdd.RDD[(Int, Int)] = MapPartitionsRDD[795] at map at <console>:64\npredictions: org.apache.spark.rdd.RDD[((Int, Int), Double)] = MapPartitionsRDD[805] at map at <console>:84\nratingsAndPredictions: org.apache.spark.rdd.RDD[((Int, Int), (Double, Double))] = MapPartitionsRDD[809] at join at <console>:88\n"}]},"apps":[],"jobName":"paragraph_1544408239283_-1474372526","id":"20181206-034503_647953150","dateCreated":"2018-12-10T02:17:19+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:4643"},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1544432400343_167336797","id":"20181210-090000_630618562","dateCreated":"2018-12-10T09:00:00+0000","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:4644"},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1544432400306_536915058","id":"20181210-090000_1838733007","dateCreated":"2018-12-10T09:00:00+0000","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:4645"},{"text":"import org.apache.spark.mllib.evaluation.RegressionMetrics\r\n // 创建预测评分-实际评分RDD\r\n val predictedAndTrue = ratingsAndPredictions.map { case ((user, product), (actual, predicted)) => (actual, predicted) }\r\n // 创建RegressionMetrics对象\r\n val regressionMetrics = new RegressionMetrics(predictedAndTrue)\r\n  \r\n // 打印MSE和RMSE\r\n println(\"Mean Squared Error = \" + regressionMetrics.meanSquaredError)\r\n println(\"Root Mean Squared Error = \" + regressionMetrics.rootMeanSquaredError)","user":"anonymous","dateUpdated":"2018-12-10T02:17:19+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"import org.apache.spark.mllib.evaluation.RegressionMetrics\npredictedAndTrue: org.apache.spark.rdd.RDD[(Double, Double)] = MapPartitionsRDD[810] at map at <console>:90\nregressionMetrics: org.apache.spark.mllib.evaluation.RegressionMetrics = org.apache.spark.mllib.evaluation.RegressionMetrics@410815f9\norg.apache.spark.SparkException: Job aborted due to stage failure: Task 58 in stage 3121.0 failed 4 times, most recent failure: Lost task 58.3 in stage 3121.0 (TID 31834, ip-172-31-3-65.ec2.internal, executor 155): ExecutorLostFailure (executor 155 exited caused by one of the running tasks) Reason: Container marked as failed: container_1544146771303_0001_01_000316 on host: ip-172-31-3-65.ec2.internal. Exit status: 50. Diagnostics: Exception from container-launch.\nContainer id: container_1544146771303_0001_01_000316\nExit code: 50\nStack trace: ExitCodeException exitCode=50:\n\tat org.apache.hadoop.util.Shell.runCommand(Shell.java:972)\n\tat org.apache.hadoop.util.Shell.run(Shell.java:869)\n\tat org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:1170)\n\tat org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:235)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:299)\n\tat org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:83)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\n\nContainer exited with a non-zero exit code 50\n\nDriver stacktrace:\n  at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1803)\n  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1791)\n  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1790)\n  at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n  at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n  at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1790)\n  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:871)\n  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:871)\n  at scala.Option.foreach(Option.scala:257)\n  at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:871)\n  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2024)\n  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1973)\n  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1962)\n  at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n  at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:682)\n  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2034)\n  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2131)\n  at org.apache.spark.rdd.RDD$$anonfun$fold$1.apply(RDD.scala:1098)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n  at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\n  at org.apache.spark.rdd.RDD.fold(RDD.scala:1092)\n  at org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1.apply(RDD.scala:1161)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n  at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\n  at org.apache.spark.rdd.RDD.treeAggregate(RDD.scala:1137)\n  at org.apache.spark.mllib.evaluation.RegressionMetrics.summary$lzycompute(RegressionMetrics.scala:57)\n  at org.apache.spark.mllib.evaluation.RegressionMetrics.summary(RegressionMetrics.scala:54)\n  at org.apache.spark.mllib.evaluation.RegressionMetrics.SSerr$lzycompute(RegressionMetrics.scala:65)\n  at org.apache.spark.mllib.evaluation.RegressionMetrics.SSerr(RegressionMetrics.scala:65)\n  at org.apache.spark.mllib.evaluation.RegressionMetrics.meanSquaredError(RegressionMetrics.scala:100)\n  ... 60 elided\n"}]},"apps":[],"jobName":"paragraph_1544408239283_-1052686608","id":"20181206-052853_1019152204","dateCreated":"2018-12-10T02:17:19+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:4646"},{"text":".saveAsTextFile(somePath)\n// val UsersForProduct = model.recommendUsersForProduct(10)\n\n\n","user":"anonymous","dateUpdated":"2018-12-10T02:17:19+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"ProductsForUsers: org.apache.spark.rdd.RDD[(Int, Array[org.apache.spark.mllib.recommendation.Rating])] = MapPartitionsRDD[1409] at map at MatrixFactorizationModel.scala:218\n<console>:145: error: value recommendForUserSubset is not a member of org.apache.spark.mllib.recommendation.MatrixFactorizationModel\n       val recommendForSubsetDF = model.recommendForUserSubset(Array(1,2), 10)\n                                        ^\n"}]},"apps":[],"jobName":"paragraph_1544408239285_-595411794","id":"20181206-062956_380252158","dateCreated":"2018-12-10T02:17:19+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:4647"}],"name":"ETL","id":"2DYEPWW7W","noteParams":{},"noteForms":{},"angularObjects":{"spark:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}