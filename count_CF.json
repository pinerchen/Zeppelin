{"paragraphs":[{"text":"val whole_count = productIndexer.fit(indexed).transform(indexed)\nval transform_count = whole_count.select($\"userID\".cast(\"int\"),$\"productID\".cast(\"int\"),$\"rating\")\nval table_c = transform_count.groupBy(\"userID\",\"productID\").agg(count(\"rating\").alias(\"rating\"))\n\nval unique_product_c = table_c.dropDuplicates(\"productID\") //留下唯一productID  (A)\nval unique_user_c = table_c.dropDuplicates(\"userID\") //留下唯一userID\nval join_c = unique_user_c.union(unique_product) //兩個資料表append\nval unique_product_user_c = join_c.dropDuplicates() //重複record drop掉 -> 作為train set\n\nval test_notyet_c = table_c.except(unique_product_user_c) // 待分的testset\nval Array(training, test) = test_notyet_c.randomSplit(Array[Double](0.9, 0.1))\nval train_final_c = unique_product_user_c.union(training)\nval test_final_c = test\n\nval tableRDD_c = table_c.rdd.map(r => Rating(\n  r.getAs[Int](\"userID\"), r.getAs[Int](\"productID\"), r.getAs[Double](\"rating\")\n))\n\nval trainRDD_c = train_final_c.rdd.map(r => Rating(\n  r.getAs[Int](\"userID\"), r.getAs[Int](\"productID\"), r.getAs[Double](\"rating\")\n))","user":"anonymous","dateUpdated":"2018-12-22T01:55:09+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"whole_count: org.apache.spark.sql.DataFrame = [user: string, product: string ... 3 more fields]\ntransform_count: org.apache.spark.sql.DataFrame = [userID: int, productID: int ... 1 more field]\ntable_c: org.apache.spark.sql.DataFrame = [userID: int, productID: int ... 1 more field]\nunique_product_c: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [userID: int, productID: int ... 1 more field]\nunique_user_c: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [userID: int, productID: int ... 1 more field]\njoin_c: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [userID: int, productID: int ... 1 more field]\nunique_product_user_c: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [userID: int, productID: int ... 1 more field]\ntest_notyet_c: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [userID: int, productID: int ... 1 more field]\ntraining: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [userID: int, productID: int ... 1 more field]\ntest: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [userID: int, productID: int ... 1 more field]\ntrain_final_c: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [userID: int, productID: int ... 1 more field]\ntest_final_c: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [userID: int, productID: int ... 1 more field]\ntableRDD_c: org.apache.spark.rdd.RDD[org.apache.spark.mllib.recommendation.Rating] = MapPartitionsRDD[2807] at map at <console>:67\ntrainRDD_c: org.apache.spark.rdd.RDD[org.apache.spark.mllib.recommendation.Rating] = MapPartitionsRDD[2858] at map at <console>:85\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://ip-172-31-32-158.ec2.internal:4040/jobs/job?id=378","http://ip-172-31-32-158.ec2.internal:4040/jobs/job?id=379"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1545404948777_-1611989402","id":"20181221-150908_1842451766","dateCreated":"2018-12-21T15:09:08+0000","dateStarted":"2018-12-21T15:16:54+0000","dateFinished":"2018-12-21T15:18:24+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:67454"},{"text":"def avgPrecisionK(actual:Seq[Int],predicted:Seq[Any],k:Int):Double = {\n    val predK = predicted.take(k)\n    var score = 0.0\n    var numHits = 0.0\n    for((p,i) <- predK.zipWithIndex){\n        if(actual.contains(p)){\n            numHits += 1.0\n            score += numHits / (i.toDouble + 1.0)\n        }\n    }\n    if (actual.isEmpty)\n    {\n        1.0\n    }else{\n        score / scala.math.min(actual.size,k).toDouble\n    }\n}","user":"anonymous","dateUpdated":"2018-12-21T15:28:31+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"avgPrecisionK: (actual: Seq[Int], predicted: Seq[Any], k: Int)Double\n"}]},"apps":[],"jobName":"paragraph_1545406107893_1630530318","id":"20181221-152827_150504109","dateCreated":"2018-12-21T15:28:27+0000","dateStarted":"2018-12-21T15:28:31+0000","dateFinished":"2018-12-21T15:28:33+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:67455"},{"text":"val model = ALS.trainImplicit(trainRDD, 20 ,12, 0.01 ,0.01)","user":"anonymous","dateUpdated":"2018-12-21T15:29:49+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"model: org.apache.spark.mllib.recommendation.MatrixFactorizationModel = org.apache.spark.mllib.recommendation.MatrixFactorizationModel@3b9a872\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://ip-172-31-32-158.ec2.internal:4040/jobs/job?id=417","http://ip-172-31-32-158.ec2.internal:4040/jobs/job?id=418","http://ip-172-31-32-158.ec2.internal:4040/jobs/job?id=419","http://ip-172-31-32-158.ec2.internal:4040/jobs/job?id=420","http://ip-172-31-32-158.ec2.internal:4040/jobs/job?id=421","http://ip-172-31-32-158.ec2.internal:4040/jobs/job?id=422","http://ip-172-31-32-158.ec2.internal:4040/jobs/job?id=423","http://ip-172-31-32-158.ec2.internal:4040/jobs/job?id=424","http://ip-172-31-32-158.ec2.internal:4040/jobs/job?id=425","http://ip-172-31-32-158.ec2.internal:4040/jobs/job?id=426","http://ip-172-31-32-158.ec2.internal:4040/jobs/job?id=427","http://ip-172-31-32-158.ec2.internal:4040/jobs/job?id=428","http://ip-172-31-32-158.ec2.internal:4040/jobs/job?id=429","http://ip-172-31-32-158.ec2.internal:4040/jobs/job?id=430","http://ip-172-31-32-158.ec2.internal:4040/jobs/job?id=431","http://ip-172-31-32-158.ec2.internal:4040/jobs/job?id=432","http://ip-172-31-32-158.ec2.internal:4040/jobs/job?id=433","http://ip-172-31-32-158.ec2.internal:4040/jobs/job?id=434","http://ip-172-31-32-158.ec2.internal:4040/jobs/job?id=435","http://ip-172-31-32-158.ec2.internal:4040/jobs/job?id=436","http://ip-172-31-32-158.ec2.internal:4040/jobs/job?id=437","http://ip-172-31-32-158.ec2.internal:4040/jobs/job?id=438","http://ip-172-31-32-158.ec2.internal:4040/jobs/job?id=439","http://ip-172-31-32-158.ec2.internal:4040/jobs/job?id=440","http://ip-172-31-32-158.ec2.internal:4040/jobs/job?id=441","http://ip-172-31-32-158.ec2.internal:4040/jobs/job?id=442","http://ip-172-31-32-158.ec2.internal:4040/jobs/job?id=443","http://ip-172-31-32-158.ec2.internal:4040/jobs/job?id=444","http://ip-172-31-32-158.ec2.internal:4040/jobs/job?id=445","http://ip-172-31-32-158.ec2.internal:4040/jobs/job?id=446","http://ip-172-31-32-158.ec2.internal:4040/jobs/job?id=447","http://ip-172-31-32-158.ec2.internal:4040/jobs/job?id=448"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1545405663536_-1304992426","id":"20181221-152103_1219827302","dateCreated":"2018-12-21T15:21:03+0000","dateStarted":"2018-12-21T15:29:49+0000","dateFinished":"2018-12-21T15:35:24+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:67456"},{"text":"val topKRecs = model.recommendProducts(1010,20)\n//println(topKRecs.mkString(\"n\"))\nval userBought = tableRDD.keyBy(_.user).lookup(1010)\nuserBought.sortBy(-_.rating).take(10).map(rating => (rating.product,rating.rating)).foreach(println)\n//println(moviesForUser.size)\nval actualProduct = userBought.map(_.product)\nval predictedProduct = topKRecs.map(_.product)\nval apk10 = avgPrecisionK(actualProduct,predictedProduct,10)","user":"anonymous","dateUpdated":"2018-12-21T16:24:09+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"topKRecs: Array[org.apache.spark.mllib.recommendation.Rating] = Array(Rating(1010,2,0.9293168097705607), Rating(1010,10,0.8722021033810052), Rating(1010,4,0.7744975117477273), Rating(1010,15,0.40012768181828706), Rating(1010,31,0.23191945338649028), Rating(1010,25,0.21394437030869384), Rating(1010,39,0.20719647181308454), Rating(1010,23,0.19481391078139582), Rating(1010,18,0.18681227055985053), Rating(1010,38,0.1728290754858873), Rating(1010,67,0.15636760452905013), Rating(1010,68,0.1515538905005131), Rating(1010,61,0.12199342820304152), Rating(1010,92,0.11968265244752685), Rating(1010,5,0.1113427404506831), Rating(1010,96,0.11108541967282361), Rating(1010,165,0.10492624167487219), Rating(1010,33,0.1000412354117286), Rating(1010,49,0.0955703901277382), Rating(1010,172,0.0952561978464067...userBought: Seq[org.apache.spark.mllib.recommendation.Rating] = WrappedArray(Rating(1010,4,23.7189981105504), Rating(1010,836,23.7189981105504), Rating(1010,10,24.63528884239456), Rating(1010,25,23.025850930040455), Rating(1010,18339,23.431316038115288), Rating(1010,67,22.33270374958051), Rating(1010,238,24.63528884239456), Rating(1010,2,22.33270374958051), Rating(1010,519,21.416413018006356), Rating(1010,103,23.025850930040455), Rating(1010,3551,23.431316038115288), Rating(1010,1344,24.63528884239456), Rating(1010,282,23.7189981105504), Rating(1010,3518,21.12873094572124), Rating(1010,2900,23.7189981105504), Rating(1010,3557,21.416413018006356), Rating(1010,1523,20.030118658386467), Rating(1010,68,24.63528884239456), Rating(1010,3164,20.72326583794641), Rating(1010,3611,21.416413018006...(10,24.63528884239456)\n(238,24.63528884239456)\n(1344,24.63528884239456)\n(68,24.63528884239456)\n(4,23.7189981105504)\n(836,23.7189981105504)\n(282,23.7189981105504)\n(2900,23.7189981105504)\n(18339,23.431316038115288)\n(3551,23.431316038115288)\nactualProduct: Seq[Int] = ArrayBuffer(4, 836, 10, 25, 18339, 67, 238, 2, 519, 103, 3551, 1344, 282, 3518, 2900, 3557, 1523, 68, 3164, 3611)\npredictedProduct: Array[Int] = Array(2, 10, 4, 15, 31, 25, 39, 23, 18, 38, 67, 68, 61, 92, 5, 96, 165, 33, 49, 172)\napk10: Double = 0.36666666666666664\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://ip-172-31-32-158.ec2.internal:4040/jobs/job?id=502","http://ip-172-31-32-158.ec2.internal:4040/jobs/job?id=503","http://ip-172-31-32-158.ec2.internal:4040/jobs/job?id=504"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1545405877881_-732709658","id":"20181221-152437_639819843","dateCreated":"2018-12-21T15:24:37+0000","dateStarted":"2018-12-21T16:24:09+0000","dateFinished":"2018-12-21T16:25:16+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:67457"},{"text":"val apk10 = avgPrecisionK(actualProduct,count_topSale_List,10)","user":"anonymous","dateUpdated":"2018-12-22T01:41:11+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"<console>:90: error: type mismatch;\n found   : Seq[Any]\n required: Seq[Int]\n       val apk10 = avgPrecisionK(actualProduct,count_topSale_List,10)\n                                               ^\n"}]},"apps":[],"jobName":"paragraph_1545442843998_-1691841307","id":"20181222-014043_1758309379","dateCreated":"2018-12-22T01:40:43+0000","dateStarted":"2018-12-22T01:41:11+0000","dateFinished":"2018-12-22T01:41:11+0000","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:67458"},{"text":"def avgPrecisionK(actual: Seq[Any], predicted: Seq[Any], k: Int): Double = {\n      val predK = predicted.take(k)\n      var score = 0.0\n      var numHits = 0.0\n      for ((p, i) <- predK.zipWithIndex) {\n        if (actual.contains(p)) {\n          numHits += 1.0\n          score += numHits / (i.toDouble + 1.0)\n        }\n      }\n      if (actual.isEmpty) {\n        1.0\n      } else {\n        score / scala.math.min(actual.size, k).toDouble\n      }\n    }\n    \n    \n    \ndef MAPK_10(model: MatrixFactorizationModel, ratings: RDD[Rating]) = {\n    val itemFactors = model.productFeatures.map { case (id, factor) => factor }.collect()\n    val itemMatrix = new DoubleMatrix(itemFactors)\n    val imBroadcast = sc.broadcast(itemMatrix)\n    val allRecs = model.userFeatures.map{ case (userId, array) =>\n  val userVector = new DoubleMatrix(array)\n  val scores = imBroadcast.value.mmul(userVector)\n  val sortedWithId = scores.data.zipWithIndex.sortBy(-_._1)\n  val recommendedIds = sortedWithId.map(_._2 + 1).toSeq\n  (userId, recommendedIds)\n    }\n    val userMovies = ratings.map{ case Rating(user, product, rating) => (user, product) }.groupBy(_._1)\n    val K = 10\n    val MAPK = allRecs.join(userMovies).map{ case (userId, (predicted, actualWithIds)) =>\n      val actual = actualWithIds.map(_._2).toSeq\n      avgPrecisionK(actual, predicted, K)\n    }.reduce(_ + _) / allRecs.count\n    MAPK\n}\nMAPK_10(model,count_topSale_List)","user":"anonymous","dateUpdated":"2018-12-22T01:44:50+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"avgPrecisionK: (actual: Seq[Int], predicted: Seq[Int], k: Int)Double\nMAPK_10: (model: org.apache.spark.mllib.recommendation.MatrixFactorizationModel, ratings: org.apache.spark.rdd.RDD[org.apache.spark.mllib.recommendation.Rating])Double\nres405: Double = 0.002193078897539085\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://ip-172-31-32-158.ec2.internal:4040/jobs/job?id=470","http://ip-172-31-32-158.ec2.internal:4040/jobs/job?id=471","http://ip-172-31-32-158.ec2.internal:4040/jobs/job?id=472"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1545407157324_1654615757","id":"20181221-154557_232545247","dateCreated":"2018-12-21T15:45:57+0000","dateStarted":"2018-12-21T15:46:50+0000","dateFinished":"2018-12-21T15:49:29+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:67459"},{"text":"val top_user = table_c.filter(\"userID <= 100\").toDF()\nval top_user_RDD = top_user.rdd.map(r => Rating(\n  r.getAs[Int](\"userID\"), r.getAs[Int](\"productID\"), r.getAs[Double](\"rating\")\n))","user":"anonymous","dateUpdated":"2018-12-21T16:45:46+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"top_user: org.apache.spark.sql.DataFrame = [userID: int, productID: int ... 1 more field]\ntop_user_RDD: org.apache.spark.rdd.RDD[org.apache.spark.mllib.recommendation.Rating] = MapPartitionsRDD[3555] at map at <console>:69\n"}]},"apps":[],"jobName":"paragraph_1545407493320_1240890227","id":"20181221-155133_1575971502","dateCreated":"2018-12-21T15:51:33+0000","dateStarted":"2018-12-21T16:45:46+0000","dateFinished":"2018-12-21T16:46:00+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:67460"},{"text":"MAPK_10(model,top_user_RDD)","user":"anonymous","dateUpdated":"2018-12-22T01:45:10+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"org.apache.spark.SparkException: Job aborted due to stage failure: Task 22 in stage 7064.0 failed 4 times, most recent failure: Lost task 22.3 in stage 7064.0 (TID 192841, ip-172-31-35-37.ec2.internal, executor 1606): java.lang.ClassCastException\n\nDriver stacktrace:\n  at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1803)\n  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1791)\n  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1790)\n  at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n  at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n  at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1790)\n  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:871)\n  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:871)\n  at scala.Option.foreach(Option.scala:257)\n  at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:871)\n  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2024)\n  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1973)\n  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1962)\n  at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n  at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:682)\n  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2034)\n  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2131)\n  at org.apache.spark.rdd.RDD$$anonfun$reduce$1.apply(RDD.scala:1035)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n  at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\n  at org.apache.spark.rdd.RDD.reduce(RDD.scala:1017)\n  at MAPK_10(<console>:108)\n  ... 58 elided\nCaused by: java.lang.ClassCastException\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://ip-172-31-32-158.ec2.internal:4040/jobs/job?id=522"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1545443090776_2114925880","id":"20181222-014450_1382146740","dateCreated":"2018-12-22T01:44:50+0000","dateStarted":"2018-12-22T01:45:10+0000","dateFinished":"2018-12-22T01:45:28+0000","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:67461"},{"text":"sqlContext.clearCache()","user":"anonymous","dateUpdated":"2018-12-22T02:06:07+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1545409975655_-1584984672","id":"20181221-163255_1644940049","dateCreated":"2018-12-21T16:32:55+0000","dateStarted":"2018-12-22T02:06:07+0000","dateFinished":"2018-12-22T02:06:14+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:67462"},{"text":"//val top_sale_c = train_final_c.groupBy(\"productID\").agg(count(\"rating\").alias(\"rating\")).sort($\"rating\".desc)\nval count_topSale_List = count_top_sale.select(\"productID\").collect().map(_(0)).toSeq","user":"anonymous","dateUpdated":"2018-12-22T01:59:46+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"count_topSale_List: Seq[Any] = WrappedArray(0, 1, 2, 3, 5, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 19, 17, 16, 18, 20, 21, 23, 22, 24, 25, 26, 30, 29, 27, 28, 32, 31, 34, 33, 35, 36, 42, 41, 38, 37, 43, 39, 40, 44, 48, 46, 50, 45, 47, 51, 49, 52, 53, 55, 54, 60, 56, 57, 63, 61, 59, 58, 69, 62, 65, 68, 64, 66, 67, 71, 80, 70, 72, 73, 74, 86, 82, 79, 75, 81, 77, 78, 76, 83, 87, 92, 89, 88, 96, 84, 95, 85, 90, 99, 107, 98, 103, 93, 91, 109, 97, 111, 102, 112, 100, 104, 94, 101, 131, 106, 116, 108, 113, 124, 117, 127, 110, 114, 105, 129, 118, 128, 115, 126, 135, 123, 120, 134, 121, 125, 132, 122, 130, 119, 139, 133, 149, 136, 155, 148, 138, 153, 157, 151, 144, 150, 147, 137, 143, 158, 145, 142, 141, 140, 164, 154, 163, 152, 159, 177, 166, 146, 156, 172, 182, 167, 168, 160, 165, 161, 171, 180..."}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://ip-172-31-32-158.ec2.internal:4040/jobs/job?id=527","http://ip-172-31-32-158.ec2.internal:4040/jobs/job?id=528","http://ip-172-31-32-158.ec2.internal:4040/jobs/job?id=529"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1545405414949_-455112338","id":"20181221-151654_1937594546","dateCreated":"2018-12-21T15:16:54+0000","dateStarted":"2018-12-22T01:59:46+0000","dateFinished":"2018-12-22T02:02:41+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:67463"},{"text":"def avgPrecisionK(actual: Seq[Any], predicted: Seq[Any], k: Int): Double = {\n      val predK = predicted.take(k)\n      var score = 0.0\n      var numHits = 0.0\n      for ((p, i) <- predK.zipWithIndex) {\n        if (actual.contains(p)) {\n          numHits += 1.0\n          score += numHits / (i.toDouble + 1.0)\n        }\n      }\n      if (actual.isEmpty) {\n        1.0\n      } else {\n        score / scala.math.min(actual.size, k).toDouble\n      }\n    }\n    \n\ndef count_top_MAPK_10(model: MatrixFactorizationModel, ratings: RDD[Rating]) = {\n    val itemFactors = model.productFeatures.map { case (id, factor) => factor }.collect()\n    val itemMatrix = new DoubleMatrix(itemFactors)\n    val imBroadcast = sc.broadcast(itemMatrix)\n    val allRecs = model.userFeatures.map{ case (userId, array) =>\n  val userVector = new DoubleMatrix(array)\n  val scores = imBroadcast.value.mmul(userVector)\n  val sortedWithId = scores.data.zipWithIndex.sortBy(-_._1)\n  val recommendedIds = sortedWithId.map(_._2 + 1).toSeq\n  (userId, recommendedIds)\n    }\n    val userMovies = ratings.map{ case Rating(user, product, rating) => (user, product) }.groupBy(_._1)\n    val K = 10\n    val MAPK = allRecs.join(userMovies).map{ case (userId, (predicted, actualWithIds)) =>\n      val actual = actualWithIds.map(_._2).toSeq\n      avgPrecisionK(actual, count_topSale_List, K)\n    }.reduce(_ + _) / allRecs.count\n    MAPK\n}\nMAPK_10(model,top_user_RDD)","user":"anonymous","dateUpdated":"2018-12-22T02:09:07+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"avgPrecisionK: (actual: Seq[Any], predicted: Seq[Any], k: Int)Double\ncount_top_MAPK_10: (model: org.apache.spark.mllib.recommendation.MatrixFactorizationModel, ratings: org.apache.spark.rdd.RDD[org.apache.spark.mllib.recommendation.Rating])Double\norg.apache.spark.SparkException: Job aborted due to stage failure: Task 57 in stage 7152.0 failed 4 times, most recent failure: Lost task 57.3 in stage 7152.0 (TID 200665, ip-172-31-35-37.ec2.internal, executor 1604): java.lang.ClassCastException\n\nDriver stacktrace:\n  at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1803)\n  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1791)\n  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1790)\n  at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n  at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n  at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1790)\n  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:871)\n  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:871)\n  at scala.Option.foreach(Option.scala:257)\n  at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:871)\n  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2024)\n  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1973)\n  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1962)\n  at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n  at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:682)\n  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2034)\n  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2131)\n  at org.apache.spark.rdd.RDD$$anonfun$reduce$1.apply(RDD.scala:1035)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n  at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\n  at org.apache.spark.rdd.RDD.reduce(RDD.scala:1017)\n  at MAPK_10(<console>:108)\n  ... 58 elided\nCaused by: java.lang.ClassCastException\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://ip-172-31-32-158.ec2.internal:4040/jobs/job?id=530"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1545443509540_1006473435","id":"20181222-015149_876673687","dateCreated":"2018-12-22T01:51:49+0000","dateStarted":"2018-12-22T02:03:56+0000","dateFinished":"2018-12-22T02:04:16+0000","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:67464"},{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1545444303926_-1572903224","id":"20181222-020503_800069281","dateCreated":"2018-12-22T02:05:03+0000","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:67466"}],"name":"count_CF","id":"2E22ESAGC","noteParams":{},"noteForms":{},"angularObjects":{"spark:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}