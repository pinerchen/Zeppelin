{"paragraphs":[{"text":"%dep\r\nz.load(\"org.scalanlp:jblas:1.2.1\")\r\n","user":"anonymous","dateUpdated":"2018-12-20T08:49:50+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"res0: org.apache.zeppelin.dep.Dependency = org.apache.zeppelin.dep.Dependency@3c645751\n"}]},"apps":[],"jobName":"paragraph_1545295790317_-1828866904","id":"20181212-015843_1688763497","dateCreated":"2018-12-20T08:49:50+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:7964"},{"text":"// 导入jblas库中的矩阵类\nimport org.jblas.DoubleMatrix\n// 定义相似度函数\ndef cosineSimilarity(vec1: DoubleMatrix, vec2: DoubleMatrix): Double = {\n    vec1.dot(vec2) / (vec1.norm2() * vec2.norm2())\n}\n","user":"anonymous","dateUpdated":"2018-12-20T08:49:50+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.jblas.DoubleMatrix\ncosineSimilarity: (vec1: org.jblas.DoubleMatrix, vec2: org.jblas.DoubleMatrix)Double\n"}]},"apps":[],"jobName":"paragraph_1545295790329_1576755354","id":"20181212-015920_1065716449","dateCreated":"2018-12-20T08:49:50+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7965"},{"text":"import java.io.File\nimport scala.io.Source\nimport org.apache.log4j.Logger\nimport org.apache.log4j.Level\n\nimport org.apache.spark.ml.fpm.FPGrowth\nimport org.apache.spark.ml.feature.StringIndexer\nimport org.apache.spark.ml.feature.VectorAssembler\nimport org.apache.spark.broadcast.Broadcast\nimport org.apache.spark.ml.evaluation.RegressionEvaluator\nimport org.apache.spark.mllib.evaluation.RankingMetrics\n\nimport org.apache.spark.sql.functions._\nimport org.apache.spark.sql.functions.explode\nimport org.apache.spark.sql.{DataFrame, Dataset,SparkSession}\n\nimport org.apache.spark.mllib.recommendation.Rating\nimport org.apache.spark.mllib.recommendation.ALS\nimport org.apache.spark.mllib.recommendation.MatrixFactorizationModel\nimport org.apache.spark.sql.Row\n\nimport org.apache.spark.SparkConf\nimport org.apache.spark.SparkContext\nimport org.apache.spark.SparkContext._\nimport org.apache.spark.broadcast.Broadcast\nimport org.apache.spark.rdd.RDD","user":"anonymous","dateUpdated":"2018-12-20T08:49:50+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import java.io.File\nimport scala.io.Source\nimport org.apache.log4j.Logger\nimport org.apache.log4j.Level\nimport org.apache.spark.ml.fpm.FPGrowth\nimport org.apache.spark.ml.feature.StringIndexer\nimport org.apache.spark.ml.feature.VectorAssembler\nimport org.apache.spark.broadcast.Broadcast\nimport org.apache.spark.ml.evaluation.RegressionEvaluator\nimport org.apache.spark.mllib.evaluation.RankingMetrics\nimport org.apache.spark.sql.functions._\nimport org.apache.spark.sql.functions.explode\nimport org.apache.spark.sql.{DataFrame, Dataset, SparkSession}\nimport org.apache.spark.mllib.recommendation.Rating\nimport org.apache.spark.mllib.recommendation.ALS\nimport org.apache.spark.mllib.recommendation.MatrixFactorizationModel\nimport org.apache.spark.sql.Row\nimport org.apache.spark.SparkConf\nimport org.apache.spark.SparkContext\nimport org.apache.spark.SparkContext._\nimport org.apache.spark.broadcast.Broadcast\nimport org.apache.spark.rdd.RDD\n"}]},"apps":[],"jobName":"paragraph_1545295790329_1754781523","id":"20181212-015934_389368932","dateCreated":"2018-12-20T08:49:50+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7966"},{"text":"//raw dataset\n/*\nval transaction = spark.read.option(\"header\",\"true\").csv(\"s3://input-smart-find/Quotations-110818-S.csv\").select($\"Quotation: Quotation ID\".alias(\"user\"), $\"Product: Product Family\".alias(\"product\"),$\"Display Quantity\".alias(\"number\")).groupBy(\"user\",\"product\").agg(sum(\"number\").alias(\"rating\")).toDF()\n val product_description = spark.read.option(\"header\",\"true\").csv(\"s3://input-smart-find/products - 110818-s.csv\").select($\"Product Family\".alias(\"product\"), $\"Product Description\".alias(\"product_description\"))\n\nval userIndexer = new StringIndexer().setInputCol(\"user\").setOutputCol(\"userID\")\nval indexed = userIndexer.fit(transaction).transform(transaction)\nval productIndexer = new StringIndexer().setInputCol(\"product\").setOutputCol(\"productID\")\n*/\nval whole = productIndexer.fit(indexed).transform(indexed).withColumn(\"log\",expr(\"log(1+(rating/0.00001))\"))\n\n//whole.printSchema()\n//whole.show(10)\n\nval transform = whole.select($\"userID\".cast(\"int\"),$\"productID\".cast(\"int\"),$\"log\")\nval table = transform.groupBy(\"userID\",\"productID\").agg(sum(\"log\").alias(\"rating\")).toDF()","user":"anonymous","dateUpdated":"2018-12-20T08:49:50+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"whole: org.apache.spark.sql.DataFrame = [user: string, product: string ... 4 more fields]\ntransform: org.apache.spark.sql.DataFrame = [userID: int, productID: int ... 1 more field]\ntable: org.apache.spark.sql.DataFrame = [userID: int, productID: int ... 1 more field]\n"}]},"apps":[],"jobName":"paragraph_1545295790330_307740213","id":"20181212-020008_856232412","dateCreated":"2018-12-20T08:49:50+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7967"},{"text":"\nval indexer_map = whole.drop(\"log\").toDF()\nindexer_map.write.option(\"header\",\"true\").format(\"csv\").mode(\"overwrite\").save(\"s3://find-smart-input/indexerMap.csv\")\n","user":"anonymous","dateUpdated":"2018-12-20T08:49:50+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"indexer_map: org.apache.spark.sql.DataFrame = [user: string, product: string ... 3 more fields]\n"}]},"apps":[],"jobName":"paragraph_1545295790330_-293724381","id":"20181218-035151_195707821","dateCreated":"2018-12-20T08:49:50+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7968"},{"text":"indexer_map.show()","user":"anonymous","dateUpdated":"2018-12-20T08:49:50+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+----------+----------+------+-------+---------+\n|      user|   product|rating| userID|productID|\n+----------+----------+------+-------+---------+\n|Q-00006876|10MQS79500| 150.0| 3545.0|  12144.0|\n|Q-00004324|4Z90Q25510| 500.0| 7696.0|  21270.0|\n|Q-00018356|10LKPAT6EU|  16.0| 5969.0|   1140.0|\n|Q-00028520|4X30H56828|   5.0|14868.0|    231.0|\n|Q-00009760|4XH0N04885| 100.0|13316.0|    746.0|\n|Q-00022082|   0A36536|  50.0| 2245.0|     61.0|\n|Q-00063689|   39Y7937|   4.0| 4971.0|    123.0|\n|Q-00017806|10QYPAT1UK| 500.0|12599.0|     29.0|\n|Q-00074595|7Y37A01086|   1.0|  591.0|    452.0|\n|Q-00054445|61A6MAT3EU|  15.0|17770.0|      7.0|\n|Q-00004794|20K3S18700| 200.0|  647.0|   3399.0|\n|Q-00068740|20L5000APG|  10.0| 8583.0|    656.0|\n|Q-00057297|20LTS0VK00|  50.0|26254.0|   7177.0|\n|Q-00010483|30BH000FUK|   3.0| 2056.0|   3176.0|\n|Q-00039557|4XF0P01010|  50.0|12651.0|   1521.0|\n|Q-00054097|20L5000AIV|  10.0| 7337.0|    998.0|\n|Q-00058280|40AF0135UK|2000.0|   71.0|     11.0|\n|Q-00057009|20LAS29100|  20.0|16566.0|  22565.0|\n|Q-00002245|40A00065UK|  50.0|27443.0|    145.0|\n|Q-00003451|20HES19B00|  50.0|  191.0|  11340.0|\n+----------+----------+------+-------+---------+\nonly showing top 20 rows\n\n"}]},"apps":[],"jobName":"paragraph_1545295790330_-1715786226","id":"20181218-052057_538022884","dateCreated":"2018-12-20T08:49:50+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7969"},{"text":"//whole.show(5)\n","user":"anonymous","dateUpdated":"2018-12-20T08:49:50+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+-------+-----------------+-----------------+------------------+\n|summary|           userID|        productID|            rating|\n+-------+-----------------+-----------------+------------------+\n|  count|           140062|           140062|            140062|\n|   mean|6952.679763247705| 3182.26753866145|15.199115814609756|\n| stddev|8414.775901249903|5448.523067208439|  2.04591388984925|\n|    min|                0|                0|               0.0|\n|    max|            33983|            24208|21.821878125947855|\n+-------+-----------------+-----------------+------------------+\n\n"}]},"apps":[],"jobName":"paragraph_1545295790330_-994124908","id":"20181218-021654_1783865405","dateCreated":"2018-12-20T08:49:50+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7970"},{"text":"// table.count() //140062\nval numUsers = table.select(table.col(\"userID\")).distinct().count() \nval numProducts = table.select(table.col(\"productID\")).distinct().count()\n//numUsers //33984\n// numProducts //24209\n\n/*\n+------+---------+\n|unique|unique   |\n|user  |product  |\n+------+---------+\n| 33984|    24209|\n+------+---------+\n\n\n\n*/\n","user":"anonymous","dateUpdated":"2018-12-20T08:49:50+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"numUsers: Long = 33984\nnumProducts: Long = 24209\n"}]},"apps":[],"jobName":"paragraph_1545295790333_433976941","id":"20181212-023543_1975592944","dateCreated":"2018-12-20T08:49:50+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7971"},{"text":"// filter某用戶在某產品購買數量最多的紀錄\n//whole.sort($\"rating\".desc).show \n/*\n+----------+----------+-------+-------+---------+------------------+\n|      user|   product| rating| userID|productID|               log|\n+----------+----------+-------+-------+---------+------------------+\n|Q-00030883|10M4S00R00|30000.0|14060.0|  10806.0|21.821878125947855|\n|Q-00063632|61B7JAT6EU|30000.0|17747.0|     60.0|21.821878125947855|\n|Q-00063632|61CAKAT1EU|30000.0|17747.0|    207.0|21.821878125947855|\n|Q-00030883|10QYPAT1EU|30000.0|14060.0|     26.0|21.821878125947855|\n|Q-00068476|20LTS6P200|29200.0|10726.0|  23877.0|21.794849453569068|\n|Q-00036576|4XE0G97138|29200.0|18963.0|     62.0|21.794849453569068|\n|Q-00068476|4XE0G97138|29200.0|10726.0|     62.0|21.794849453569068|\n|Q-00068476| 888015205|29200.0|10726.0|    153.0|21.794849453569068|\n|Q-00036576| 888015205|29200.0|18963.0|    153.0|21.794849453569068|\n|Q-00064016| 888015205|28000.0|18382.0|    153.0|21.752885254484713|\n+----------+----------+-------+-------+---------+\n*/\n\n\n// filter 消費數量最高的前10大用戶\nval user_ratingSum = whole.groupBy(\"userID\").agg(sum(\"rating\").alias(\"Total_Amount\")).sort($\"Total_Amount\".desc).show\nval user_ratingCount = whole.groupBy(\"userID\").agg(count(\"rating\").alias(\"Rating_count\"))\n/*\n+------+------------+\n|userID|Total_Amount|\n+------+------------+\n|   3.0|    537000.0|\n|  54.0|    344450.0|\n| 282.0|    250800.0|\n| 334.0|    230800.0|\n|  71.0|    173000.0|\n| 719.0|    170800.0|\n|1054.0|    160000.0|\n| 685.0|    158000.0|\n| 707.0|    154000.0|\n| 760.0|    148000.0|\n+------+------------+\n\n*/\n\n// top 10 sale\n//val top_sale =  training_final.groupBy(\"productID\").agg(sum(\"rating\").alias(\"Total_Amount\")).sort($\"Total_Amount\".desc)\n/*\n+---------+------------+\n|productID|Total_Amount|\n+---------+------------+\n|      0.0|    577598.0|\n|      1.0|    492920.0|\n|      5.0|    288709.0|\n|      4.0|    272528.0|\n|      3.0|    262920.0|\n|      8.0|    236287.0|\n|     18.0|    228088.0|\n|     11.0|    221678.0|\n|      2.0|    213747.0|\n|    153.0|    201092.0|\n+---------+------------+\n\n*/","user":"anonymous","dateUpdated":"2018-12-20T08:49:50+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+------+------------+\n|userID|Total_Amount|\n+------+------------+\n|   3.0|    537000.0|\n|  54.0|    344450.0|\n| 282.0|    250800.0|\n| 334.0|    230800.0|\n|  71.0|    173000.0|\n| 719.0|    170800.0|\n|1054.0|    160000.0|\n| 685.0|    158000.0|\n| 707.0|    154000.0|\n| 760.0|    148000.0|\n|  19.0|    135714.0|\n|  20.0|    134614.0|\n|  23.0|    125814.0|\n| 116.0|    120000.0|\n|1081.0|    114937.0|\n|  69.0|    110150.0|\n|  13.0|     90000.0|\n|  14.0|     90000.0|\n|  11.0|     90000.0|\n|  10.0|     90000.0|\n+------+------------+\nonly showing top 20 rows\n\nuser_ratingSum: Unit = ()\nuser_ratingCount: org.apache.spark.sql.DataFrame = [userID: double, Rating_count: bigint]\n"}]},"apps":[],"jobName":"paragraph_1545295790334_1931940029","id":"20181212-020233_1752433362","dateCreated":"2018-12-20T08:49:50+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7972"},{"text":"/*\r\n\r\n// NOTE: add minimum and maximum values to thresholds\r\nval thresholds: Array[Double] = Array(Double.MinValue, 0.0) ++ (((0.0 until 600000 by 100000).toArray ++ Array(Double.MaxValue)).map(_.toDouble))\r\n\r\n// Convert DataFrame to RDD and calculate histogram values\r\nval _tmpHist = top_sale.\r\n    select($\"Total_Amount\" cast \"double\").\r\n    rdd.map(r => r.getDouble(0)).\r\n    histogram(thresholds)\r\n\r\n// Result DataFrame contains `from`, `to` range and the `value`.\r\nval histogram = sc.parallelize((thresholds, thresholds.tail, _tmpHist).zipped.toList).toDF(\"from\", \"to\", \"value\")","user":"anonymous","dateUpdated":"2018-12-20T08:49:50+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"thresholds: Array[Double] = Array(-1.7976931348623157E308, 0.0, 0.0, 100000.0, 200000.0, 300000.0, 400000.0, 500000.0, 1.7976931348623157E308)\n_tmpHist: Array[Long] = Array(0, 0, 24168, 31, 8, 0, 1, 1)\nhistogram: org.apache.spark.sql.DataFrame = [from: double, to: double ... 1 more field]\n"}]},"apps":[],"jobName":"paragraph_1545295790334_1323055626","id":"20181214-093158_1815709665","dateCreated":"2018-12-20T08:49:50+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7973"},{"text":"val unique_product = table.dropDuplicates(\"productID\") //留下唯一productID  (A)\nval unique_user = table.dropDuplicates(\"userID\") //留下唯一userID\nval join = unique_user.union(unique_product) //兩個資料表append\nval unique_product_user = join.dropDuplicates() //重複record drop掉 -> 作為train set\n\nval test_notyet = table.except(unique_product_user) // 待分的testset\nval Array(training, test) = test_notyet.randomSplit(Array[Double](0.9, 0.1))\nval training_final = unique_product_user.union(training)\nval testing = test\n\nval numUsers = unique_product_user.select(training_final.col(\"userID\")).distinct().count() //確認數據有相同數量unique user\nval numProducts = unique_product_user.select(training_final.col(\"productID\")).distinct().count() //確認數據有相同數量unique product\n//numUsers: Long = 33984\n//numProducts: Long = 24209","user":"anonymous","dateUpdated":"2018-12-20T08:49:50+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"unique_product: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [userID: int, productID: int ... 1 more field]\nunique_user: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [userID: int, productID: int ... 1 more field]\njoin: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [userID: int, productID: int ... 1 more field]\nunique_product_user: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [userID: int, productID: int ... 1 more field]\ntest_notyet: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [userID: int, productID: int ... 1 more field]\ntraining: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [userID: int, productID: int ... 1 more field]\ntest: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [userID: int, productID: int ... 1 more field]\ntraining_final: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [userID: int, productID: int ... 1 more field]\ntesting: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [userID: int, productID: int ... 1 more field]\nnumUsers: Long = 33984\nnumProducts: Long = 24209\n"}]},"apps":[],"jobName":"paragraph_1545295790334_1074575261","id":"20181213-021529_782513074","dateCreated":"2018-12-20T08:49:50+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7974"},{"text":"//確認數據集數量、且包含unique userID & productID.\n\nval numTrain = training_final.count()\nval numTest = testing.count()\n\n// train: 131169\n// test: 8948","user":"anonymous","dateUpdated":"2018-12-20T08:49:50+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"numTrain: Long = 131169\nnumTest: Long = 8948\n"}]},"apps":[],"jobName":"paragraph_1545295790334_1640003138","id":"20181213-030530_760267561","dateCreated":"2018-12-20T08:49:50+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7975"},{"text":"// val training = train.union(unique_product_tr.toDF())\nval tableRDD = table.rdd.map(r => Rating(\n  r.getAs[Int](\"userID\"), r.getAs[Int](\"productID\"), r.getAs[Double](\"rating\")\n))\n\nval trainRDD = training_final.rdd.map(r => Rating(\n  r.getAs[Int](\"userID\"), r.getAs[Int](\"productID\"), r.getAs[Double](\"rating\")\n))\n\n/*\nval testRDD = testing.rdd.map(r => Rating(\n  r.getAs[Int](\"userID\"), r.getAs[Int](\"productID\"), r.getAs[Double](\"rating\")\n))\n","user":"anonymous","dateUpdated":"2018-12-20T08:49:50+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"INCOMPLETE","msg":[{"type":"TEXT","data":"tableRDD: org.apache.spark.rdd.RDD[org.apache.spark.mllib.recommendation.Rating] = MapPartitionsRDD[290] at map at <console>:66\ntrainRDD: org.apache.spark.rdd.RDD[org.apache.spark.mllib.recommendation.Rating] = MapPartitionsRDD[335] at map at <console>:77\n"}]},"apps":[],"jobName":"paragraph_1545295790334_1726310498","id":"20181212-043339_2062055690","dateCreated":"2018-12-20T08:49:50+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7976"},{"text":"/*\r\ndef computeRmse(model: MatrixFactorizationModel, data: RDD[Rating], n: Long): Double = {\r\n    val predictions: RDD[Rating] = model.predict(data.map(x => (x.user, x.product)))\r\n    val predictionsAndRatings = predictions.map(x => ((x.user, x.product), x.rating))\r\n      .join(data.map(x => ((x.user, x.product), x.rating)))\r\n      .values\r\n    math.sqrt(predictionsAndRatings.map(x => (x._1 - x._2) * (x._1 - x._2)).reduce(_ + _) / n)\r\n  }","user":"anonymous","dateUpdated":"2018-12-20T08:49:50+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"INCOMPLETE","msg":[]},"apps":[],"jobName":"paragraph_1545295790334_-34396014","id":"20181212-052939_2138673281","dateCreated":"2018-12-20T08:49:50+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7977"},{"text":"// percentile ranking function\r\ndef expectedPercentileRanking(model: MatrixFactorizationModel, ratings: RDD[Rating]) = {\r\n    val itemFactors = model.productFeatures.collect() //itemFactors: Array[(Int, Array[Double])]\r\n    val itemMatrix = new DoubleMatrix(itemFactors.map(_._2)) //[Double]\r\n    val imBroadCast = sc.broadcast(itemMatrix)\r\n    val itemListPerUser = ratings.groupBy(_.user).map {\r\n      case (user, ratingList) => (user, ratingList.map(rt => (rt.product, rt.rating)).toArray)\r\n    }\r\n    // itemListPerUser: [(Int, Array[(Int, Double)])]\r\n    val rankRDD = model.userFeatures.join(itemListPerUser).map {\r\n        //(Int,     (Array[Double], Array[(Int, Double)]))\r\n      case (userId, (userFeatures, itemRatingList)) =>\r\n        val userVector = new DoubleMatrix(userFeatures)\r\n        val scores = imBroadCast.value.mmul(userVector) //用戶對各產品喜好分數乘積\r\n        \r\n        val sortedWithId = scores.data.zipWithIndex.sortBy(-_._1) //A. User 產品偏好分數由大到小排列\r\n        val itemsOrderedByPref = sortedWithId.map(_._2).toSeq // B. 抓取User喜好順序的對應產品ID ex. User0 : [P4,P3,P1]\r\n        \r\n        val rankWeightedByRating = itemRatingList.map {\r\n          case (itemId, rating) =>\r\n            rating *itemsOrderedByPref.indexOf(itemId).toDouble / (itemsOrderedByPref.size - 1)\r\n        \r\n        }.sum\r\n        rankWeightedByRating\r\n    }\r\n    \r\n    //rankRDD.take(3).foreach(println)\r\n    val weightedRankOverAll = rankRDD.sum()\r\n    val sumWeight = ratings.map(_.rating).sum()\r\n    weightedRankOverAll / sumWeight\r\n    \r\n  }","user":"anonymous","dateUpdated":"2018-12-20T08:49:50+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"expectedPercentileRanking: (model: org.apache.spark.mllib.recommendation.MatrixFactorizationModel, ratings: org.apache.spark.rdd.RDD[org.apache.spark.mllib.recommendation.Rating])Double\n"}]},"apps":[],"jobName":"paragraph_1545295790335_-121696443","id":"20181213-060048_1845127949","dateCreated":"2018-12-20T08:49:50+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7978"},{"text":"// Corss Validation Model\n    val ranks = List(50)\n    val lambdas = List(150,500)\n    val alphas = List(40)\n    val numIters = List(15)\n    var bestModel: Option[MatrixFactorizationModel] = None\n    var bestRanking = 99.0\n    var bestRank = 0\n    var bestLambda = -1.0\n    var bestNumIter = -1\n    var bestAlpha = 0\n    \n   for (rank <- ranks; lambda <- lambdas; numIter <- numIters; alpha <- alphas ) {\n      val model = ALS.trainImplicit(trainRDD, rank, numIter, lambda, alpha)\n      val rank_in = expectedPercentileRanking(model, tableRDD)\n      println(\"Percentil Ranking = \" + rank_in + \" for the model trained with rank = \"\n        + rank + \n        \", lambda = \" + lambda + \n        \", alpha = \" + alpha + \n        \", and numIter = \" + numIter + \".\")\n      if (rank_in < bestRanking) {\n        bestModel = Some(model)\n        bestRanking = rank_in\n        bestRank = rank\n        bestLambda = lambda\n        bestNumIter = numIter\n        bestAlpha = alpha\n      }\n    }\n\n    val test_PercentileRanking = rank_in\n\n    println(\"The best model was trained with ranking = \" + bestRanking + \" and rank = \" + bestRank + \" and lambda = \" + bestLambda\n      + \", and numIter = \" + bestNumIter + \", and its RMSE on the test set is \" + test_PercentileRanking + \".\")","user":"anonymous","dateUpdated":"2018-12-20T08:49:50+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"ranks: List[Int] = List(50)\nlambdas: List[Int] = List(150, 500)\nalphas: List[Int] = List(40)\nnumIters: List[Int] = List(15)\nbestModel: Option[org.apache.spark.mllib.recommendation.MatrixFactorizationModel] = None\nbestRanking: Double = 99.0\nbestRank: Int = 0\nbestLambda: Double = -1.0\nbestNumIter: Int = -1\nbestAlpha: Int = 0\nPercentil Ranking = 0.4724633235966601 for the model trained with rank = 50, lambda = 150, alpha = 40, and numIter = 15.\nPercentil Ranking = 0.4649976804848549 for the model trained with rank = 50, lambda = 500, alpha = 40, and numIter = 15.\n<console>:50: error: not found: value rank_in\n           val test_PercentileRanking = rank_in\n                                        ^\n"}]},"apps":[],"jobName":"paragraph_1545295790335_1372400328","id":"20181213-032739_1279375246","dateCreated":"2018-12-20T08:49:50+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7979"},{"text":"//model_default tooks 5.5mins\nval seed = 1222L\nval implicitPrefs = true\nval model_default = new ALS().\nsetImplicitPrefs(implicitPrefs).\nrun(trainRDD)\n\n","user":"anonymous","dateUpdated":"2018-12-20T08:49:50+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"seed: Long = 1222\nimplicitPrefs: Boolean = true\nmodel_default: org.apache.spark.mllib.recommendation.MatrixFactorizationModel = org.apache.spark.mllib.recommendation.MatrixFactorizationModel@59054cb4\n"}]},"apps":[],"jobName":"paragraph_1545295790335_-886570188","id":"20181212-061309_180340924","dateCreated":"2018-12-20T08:49:50+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7980"},{"text":"//model\nval rank = 30\nval numIterations = 20\nval alpha = 0.01\nval lambda = 0.5\nval block = -1\nval seed = 1222L\nval implicitPrefs = true\nval model_decimal = new ALS().\n    setIterations(numIterations).\n    setBlocks(block).\n    setAlpha(alpha).\n    setLambda(lambda).\n    setRank(rank).\n    setSeed(seed).\n    setImplicitPrefs(implicitPrefs).\n    run(trainRDD)\n","user":"anonymous","dateUpdated":"2018-12-20T08:49:50+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"rank: Int = 30\nnumIterations: Int = 20\nalpha: Double = 0.01\nlambda: Double = 0.5\nblock: Int = -1\nseed: Long = 1222\nimplicitPrefs: Boolean = true\nmodel_decimal: org.apache.spark.mllib.recommendation.MatrixFactorizationModel = org.apache.spark.mllib.recommendation.MatrixFactorizationModel@1e1141e8\n"}]},"apps":[],"jobName":"paragraph_1545295790335_-1804790226","id":"20181218-025558_1838888742","dateCreated":"2018-12-20T08:49:50+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7981"},{"text":"//model_decimal\nval rank = 8\nval numIterations = 5\nval block = -1\nval seed = 1222L\nval implicitPrefs = true\nval model_decimal = new ALS().\nsetIterations(numIterations).\nsetBlocks(block).\nsetRank(rank).\nsetSeed(seed).\nsetImplicitPrefs(implicitPrefs).\nrun(trainRDD)\n","user":"anonymous","dateUpdated":"2018-12-20T08:49:50+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"rank: Int = 8\nnumIterations: Int = 5\nblock: Int = -1\nseed: Long = 1222\nimplicitPrefs: Boolean = true\nmodel_decimal: org.apache.spark.mllib.recommendation.MatrixFactorizationModel = org.apache.spark.mllib.recommendation.MatrixFactorizationModel@638cf04b\n"}]},"apps":[],"jobName":"paragraph_1545295790335_-2032175421","id":"20181218-033804_465452853","dateCreated":"2018-12-20T08:49:50+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7982"},{"text":"//model_default.userFeatures.take(3)\nmodel_decimal.userFeatures.take(3)","user":"anonymous","dateUpdated":"2018-12-20T08:49:50+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{"0":{"graph":{"mode":"table","height":88,"optionOpen":false}}},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"res222: Array[(Int, Array[Double])] = Array((0,Array(-0.07924874871969223, 0.07974139600992203, -0.08342031389474869, 0.8544738292694092, -0.5965257883071899, 0.16072046756744385, 0.5971316695213318, -0.6120902895927429, 0.16028696298599243, 0.40369266271591187, 0.5457688570022583, 0.3736405670642853, -1.0139213800430298, 0.6656785607337952, -0.21745538711547852, -0.6604974865913391, -0.9868693351745605, -0.5820733904838562, 1.2085545063018799, 0.40022745728492737, 0.5475912690162659, 0.3341904282569885, -0.09709439426660538, -0.2976132035255432, -0.7061969637870789, 0.9840803146362305, 0.7194858193397522, 0.5465829968452454, -0.5055050849914551, 0.21154338121414185)), (200,Array(-0.2697714865207672, -0.40370842814445496, -0.026851624250411987, 0.4122345745563507, 0.23954634368419647, -..."}]},"apps":[],"jobName":"paragraph_1545295790335_1294187715","id":"20181218-030117_1582787129","dateCreated":"2018-12-20T08:49:50+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7983"},{"text":"// \n// 1. top sale ranking.\n// 2. percentile ranking of testset item.\n\nval top_sale =  training_final.groupBy(\"productID\").agg(sum(\"rating\").alias(\"Total_Amount\")).sort($\"Total_Amount\".desc).drop(\"Total_Amount\")\nval topSale_List = top_sale.select(\"productID\").collect().map(_(0)).toList\n\ndef topSalePercentileRanking(TopSale: List[Any], ratings: RDD[Rating]) = {\n    \n    //val List =  whole.groupBy(\"productID\").agg(sum(\"rating\").alias(\"Total_Amount\")).sort($\"Total_Amount\".desc).drop(\"Total_Amount\")\n    //val topSale_List = top_sale.select(\"productID\").collect().map(_(0)).toList\n    \n    val itemListPerUser = ratings.groupBy(_.user).map {\n      case (user, ratingList) => (user, ratingList.map(rt => (rt.product, rt.rating)).toArray)\n    }\n    val rankRDD_top = itemListPerUser.map {\n      case (userId, itemRatingList) =>\n\n        \n        val rankWeightedByRating = itemRatingList.map {\n          case (itemId, rating) =>\n             rating * TopSale.indexOf(itemId).toDouble / (TopSale.size - 1)\n        \n        }.sum\n        rankWeightedByRating\n    }\n    //rankRDD_top.take(3).foreach(println)\n    val weightedRankOverAll = rankRDD_top.sum()\n    val sumWeight = ratings.map(_.rating).sum()\n    weightedRankOverAll / sumWeight\n    rankRDD_top.\n  }\n\n\n\n","user":"anonymous","dateUpdated":"2018-12-20T08:49:50+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"top_sale: org.apache.spark.sql.DataFrame = [productID: int]\ntopSale_List: List[Any] = List(0, 1, 2, 3, 4, 5, 6, 7, 8, 11, 9, 10, 12, 13, 14, 17, 15, 18, 19, 20, 23, 22, 21, 16, 24, 26, 25, 27, 30, 31, 32, 29, 33, 34, 28, 36, 41, 38, 39, 40, 44, 43, 49, 42, 52, 46, 35, 51, 48, 50, 56, 47, 53, 57, 55, 54, 45, 37, 61, 60, 58, 70, 63, 65, 59, 64, 66, 67, 81, 68, 69, 62, 73, 71, 75, 74, 76, 79, 83, 80, 85, 77, 78, 86, 92, 82, 84, 88, 91, 89, 94, 87, 72, 98, 102, 108, 97, 96, 110, 104, 99, 95, 105, 114, 121, 118, 129, 117, 106, 100, 128, 103, 122, 136, 115, 116, 109, 112, 107, 124, 126, 119, 127, 111, 132, 90, 134, 101, 113, 138, 131, 137, 93, 135, 155, 146, 140, 156, 150, 145, 153, 163, 152, 162, 177, 173, 148, 161, 139, 120, 175, 123, 125, 141, 130, 165, 164, 182, 149, 144, 158, 184, 172, 160, 157, 133, 171, 159, 151, 178, 143, 196, 147, 192, 207, 1...topSalePercentileRanking: (TopSale: List[Any], ratings: org.apache.spark.rdd.RDD[org.apache.spark.mllib.recommendation.Rating])Double\n"}]},"apps":[],"jobName":"paragraph_1545295790336_-747760690","id":"20181214-073100_1799197759","dateCreated":"2018-12-20T08:49:50+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7984"},{"text":"//Precision\r\n\r\nval binarizedRatings = table.map(r => Rating(r.getAs[Int](\"userID\"), r.getAs[Int](\"productID\"),\r\n  if (r.getAs[Double](\"rating\") > 0) 1.0 else 0.0)).cache()\r\n \r\n \r\n /*\r\nrank: Int = 30\r\nnumIterations: Int = 20\r\nalpha: Double = 0.01\r\nlambda: Double = 0.5\r\nblock: Int = -1\r\nseed: Long = 1222\r\nimplicitPrefs: Boolean = true\r\nval model_precision = new ALS().\r\n    setIterations(numIterations).\r\n    setBlocks(block).\r\n    setAlpha(alpha).\r\n    setLambda(lambda).\r\n    setRank(rank).\r\n    setSeed(seed).\r\n    setImplicitPrefs(implicitPrefs).\r\n    run(trainRDD)\r\n*/\r\ndef scaledRating(r: Rating): Rating = {\r\n  val scaledRating = math.max(math.min(r.rating, 1.0), 0.0)\r\n  Rating(r.user, r.product, scaledRating)\r\n}\r\n\r\nval userRecommended = model_decimal.recommendProductsForUsers(10).map { case (user, recs) =>\r\n  (user, recs.map(scaledRating))\r\n}\r\n\r\nval userProducts = binarizedRatings.groupBy((x$1) => x$1.user)\r\nval relevantDocuments = userProducts.join(userRecommended).map { case (user, (actual,\r\npredictions)) =>\r\n  (predictions.map(_.product), actual.filter(_.rating > 0.0).map(_.product).toArray)\r\n}\r\n\r\nval metrics = new RankingMetrics(relevantDocuments)\r\n\r\nArray(1, 3, 5).foreach { k =>\r\n  println(s\"Precision at $k = ${metrics.precisionAt(k)}\")\r\n}\r\n\r\n\r\n\r\n","user":"anonymous","dateUpdated":"2018-12-20T08:49:50+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"binarizedRatings: org.apache.spark.sql.Dataset[org.apache.spark.mllib.recommendation.Rating] = [user: int, product: int ... 1 more field]\nscaledRating: (r: org.apache.spark.mllib.recommendation.Rating)org.apache.spark.mllib.recommendation.Rating\nuserRecommended: org.apache.spark.rdd.RDD[(Int, Array[org.apache.spark.mllib.recommendation.Rating])] = MapPartitionsRDD[4855] at map at <console>:185\n<console>:154: error: missing parameter type\n       val userProducts = binarizedRatings.groupBy((x$1) => x$1.user)\n                                                    ^\n"}]},"apps":[],"jobName":"paragraph_1545295790336_-889897820","id":"20181218-094332_1954812300","dateCreated":"2018-12-20T08:49:50+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7985"},{"text":" //topSalePercentileRanking(topSale_List,trainRDD)\n  topSalePercentileRanking(topSale_List,tableRDD)\n  ","user":"anonymous","dateUpdated":"2018-12-20T08:49:50+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"res104: Double = 0.13167605004876726\n"}]},"apps":[],"jobName":"paragraph_1545295790336_-183142704","id":"20181214-085829_1387069036","dateCreated":"2018-12-20T08:49:50+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7986"},{"text":"\r\n//val rank_in = expectedPercentileRanking(model_default, trainRDD)\r\nval rank_out = expectedPercentileRanking(model_decimal, tableRDD)\r\n","user":"anonymous","dateUpdated":"2018-12-20T08:49:50+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"rank_out: Double = 0.4824541603797379\n"}]},"apps":[],"jobName":"paragraph_1545295790336_1110344175","id":"20181212-070031_1706859906","dateCreated":"2018-12-20T08:49:50+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7987"},{"user":"anonymous","dateUpdated":"2018-12-20T08:49:50+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1545295790336_-1925849809","id":"20181218-063203_647348150","dateCreated":"2018-12-20T08:49:50+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7988"},{"text":"val predictedRating = model_decimal.predict(991,718)\nprintln(predictedRating)","user":"anonymous","dateUpdated":"2018-12-20T08:49:50+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"predictedRating: Double = -0.055086200180631484\n-0.055086200180631484\n"}]},"apps":[],"jobName":"paragraph_1545295790336_-1496051129","id":"20181214-091517_840293925","dateCreated":"2018-12-20T08:49:50+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7989"},{"user":"anonymous","dateUpdated":"2018-12-20T08:49:50+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1545295790337_1539446269","id":"20181218-063027_1844992397","dateCreated":"2018-12-20T08:49:50+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:7990"}],"name":"MAP_Recall_unfinished","id":"2DZV78Z5X","noteParams":{},"noteForms":{},"angularObjects":{"spark:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}